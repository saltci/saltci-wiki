{"pages":[{"title":"About","date":"2020-01-11T15:16:00.000Z","path":"about/index.html","text":"关于我自己嗨呀，我好菜呀！有什么可说的呢。。。"},{"title":"Categories","date":"2020-11-27T07:02:13.814Z","path":"categories/index.html","text":""},{"title":"Tags","date":"2020-11-27T07:02:13.818Z","path":"tags/index.html","text":""}],"posts":[{"title":"mongoengine","date":"2020-08-30T02:42:21.000Z","path":"Database/MongoDB/mongoengine/","text":"MongoEngine是MongoDB的一个ODM(Object-Document Mapper)框架,它提供了类似Django的语法来操作MongoDB数据库.MongoEngine是一个对象文档映射器(ODM),相当于一个基于SQL的对象关系映射器(ORM)pymongo来操作MongoDB数据库,但是直接把对于数据库的操作代码都写在脚本中,这会让应用的代码耦合性太强,而且不利于代码的优化管理.一般应用都是使用MVC框架来设计的,为了更好地维持MVC结构,需要把数据库操作部分作为model抽离出来,这就需要借助Mongoengine,Mongoengine提供的抽象是基于类的,创建的所有模型都是类,我们可以跟关系型数据库的Python客户端MySQLdb,以及ORM SQLAlchemy/Django ORM比较一下,PyMongo相当于MySQLdb,Mongoengine相当于SQLAlchemy,SQLAlchemy是基于MySQLdb之上的,MongoEngine是基于PyMongo的. 官方英文文档地址: http://docs.mongoengine.org/tutorial.html 文档类型document document是静态文档,这种文档定义好了之后,不能添加新的字段12345678from mongoengine import Document, StringFieldclass People(Document): title = StringField(max_length=20) meta = &#123; 'db_alias': 'db_name', # 数据库名字 'collection': 'people', # 集合的名字,如果不定义就用class的小写 &#125; DynamicDocument dynamicDocument可以实现随意添加字段的功能,但动态文档中的字段不能以_开头1234567891011121314from mongoengine import *class Page(DynamicDocument): title = StringField(max_length=200, required=True)if __name__ == '__main__': # Create a new page and add tags page = Page(title='Using MongoEngine') page.tags = ['mongodb', 'mongoengine'] page.save() # query count = Page.objects(tags='mongodb').count() print(count) EmbeddedDocument EmbeddedDocument是嵌入文档,MongoDB能够在文档中嵌入文档.嵌入文档模式并不是在数据库中真正形成一个集合,而实作为某个集合的字段出现. 1234567891011121314151617181920212223242526272829303132333435363738from mongoengine import *class User(Document): name = StringField(max_length=20) password = StringField(max_length=128)class Comment(EmbeddedDocument): content = StringField() name = StringField(max_length=120)class Article(Document): title = StringField(max_length=120, required=True) # 外键,reverse_delete_rule=CASCADE,传统数据库中的级联删除 # MapFields和DictFields当前不支持自动处理已删除的引用。 author = ReferenceField(User, reverse_delete_rule=True) tags = ListField(StringField(max_length=30)) # 列表类型,listfield内第一个参数就是限制列表中的元素类型 comments = ListField(EmbeddedDocumentField(Comment)) meta = &#123; 'allow_inheritance': True # allow_inheritance=True允许继承默认是不被允许的,当以后需要添加新的字段时,直接继承这个类就好了 &#125;if __name__ == '__main__': # 嵌入式文档添加数据的方式 user = User(name=\"jony\", password=\"123456\") user.save() article = Article(title='Mongoengine Documentation', author=user) article.tags = ['mongodb', 'python'] comment_1 = Comment(name=\"小明\", content=\"真的好棒\") comment_2 = Comment(name=\"小红\", content=\"太好了\") article.comments = [comment_1, comment_2] article.save() 结果:1234567891011121314151617181920&#123; \"_id\": ObjectId(\"5f4b5505f21838559032874f\"), \"_cls\": \"Article\", \"title\": \"Mongoengine Documentation\", \"author\": ObjectId(\"5f4b5504f21838559032874e\"), \"tags\": [ \"mongodb\", \"python\" ], \"comments\": [ &#123; \"content\": \"真的好棒\", \"name\": \"小明\" &#125;, &#123; \"content\": \"太好了\", \"name\": \"小红\" &#125; ]&#125; Fieldlistfield 支持一个列表,它的第一个参数用来指定列表中元素的类型 12class Page(Document): tags = ListField(StringField(max_length=50)) ReferenceField ReferenceField相当于传统数据库中的外键,用于关联其它集合 一对一1234567class Employee(Document): name = StringField() boss = ReferenceField('self') # 如果要引用的类名没有被定义,则使用self profile_page = ReferenceField(\"ProfilePage\") # 参数为要引用的类名class ProfilePage(Document): content = StringField() 一对多 一对多需要用ListField,也可以叫一引多,把ReferenceField放在一的集合中.123456789101112131415161718from mongoengine import *class User(Document): name = StringField()class Page(Document): content = StringField() authors = ListField(ReferenceField(User))if __name__ == '__main__': bob = User(name=\"Bob jones\").save() john = User(name=\"John smith\").save() Page(content=\"Test page\", authors=[bob, john]).save() Page(content=\"Another page\", authors=[john]).save() 级连删除 本例中的声明意味着,当删除雇员对象时,引用该雇员的ProfilePage的配置文件页也将被删除.如果删除了整批员工,则链接的所有配置文件页也将删除.默认项为:mongoengine.DO_NOTHING,不做任何操作12class ProfilePage(Document): employee = ReferenceField('Employee',reverse_delete_rule=mongoengine.CASCADE) GenericReferenceField 该字段的作用是设置某个集合用来引用任何的集合.注意：使用genericreferencefields的效率比标准referencefields稍低，因此，如果您只引用一种文档类型，则首选标准referencefield。 123456789101112131415161718192021222324from mongoengine import *class Link(Document): url = StringField()class Post(Document): title = StringField()class Bookmark(Document): bookmark_object = GenericReferenceField()if __name__ == '__main__': link = Link(url='http://www.baidu.com') link.save() post = Post(title='Using MongoEngine') post.save() Bookmark(bookmark_object=link).save() Bookmark(bookmark_object=post).save() 输出1234567891011121314151617// 1&#123; \"_id\": ObjectId(\"5f4b603ef9ed40279b019972\"), \"bookmark_object\": &#123; \"_cls\": \"Link\", \"_ref\": DBRef(\"link\", ObjectId(\"5f4b603ef9ed40279b019970\")) &#125;&#125;// 2&#123; \"_id\": ObjectId(\"5f4b603ef9ed40279b019973\"), \"bookmark_object\": &#123; \"_cls\": \"Post\", \"_ref\": DBRef(\"post\", ObjectId(\"5f4b603ef9ed40279b019971\")) &#125;&#125; LazyReferenceField 这个字段是懒惰关联字段,相当于懒加载,和迭代器作用差不多,什么时候调用fetch方法什么时候产生数据,不像referenceField字段那样直接得出数据 1234567891011121314151617from test.helper import clientfrom mongoengine import *class Address(DynamicDocument): add_name = StringField(max_length=22)class People(DynamicDocument): name = StringField(max_length=22) adds = LazyReferenceField(Address)if __name__ == '__main__': address = Address(add_name='Shanghai').save() xiaohong = People(name='小红', adds=address).save() 数据库信息12345&#123; \"_id\": ObjectId(\"5f4b64292651a4986f9b57c9\"), \"name\": \"小红\", \"adds\": ObjectId(\"5f4b64292651a4986f9b57c8\")&#125; 查询小红的地址12345# 查询小红的地址p1 = People.objects.filter(name=\"小红\").first()print(p1.adds) # 这样是获取不到地址对象的print('使用fetch:', p1.adds.fetch()) # 通过fetch方法才能获取到小红对应的地址对象print('小红的地址为:', p1.adds.fetch().add_name) # 获取地址 注: 注意使用了lazyReference字段后,获取引用的对象时要用fetch()方法来获取,但是可以直接获取它的主键值: 1234# 查询小红的地址p1 = People.objects.filter(name=\"小红\").first()print(p1.adds.id)print(p1.adds.pk) 其它Unique1234class User(Document): username = StringField(unique=True) # 唯一 first_name = StringField() last_name = StringField(unique_with='first_name') # 联合唯一 Skipping Document validation on save Mongoengine中的字段默认有检查功能,也就是valid,如果你要保存数据的时候不需要他检验可以这样设置123456789101112from mongoengine import *class Recipient(Document): name = StringField() email = EmailField()if __name__ == '__main__': recipent = Recipient(name=\"admin\", email=\"root@localhost\") # recipent.save() # will raise a ValidationError while saving recipent.save(validate=False) # won't raise a ValidationError 修改数据库的名字 默认的集合名字就是当前类的小写,如果你要更改集合的名字,可以这样操作 123class Page(Document): title = StringField(max_length=200,required=True) meta = &#123;\"collection\":\"cmsPage\"&#125; 对集合中的文档的个数和大小限制,可以这样做,默认为10M,以字节显示123class Log(Document): ip_address = StringField() meta = &#123;\"max_documents\": 1000,\"max_size\": 2000000&#125;&#125; 排序 可选地在前面加上“-”（以表示降序排序，即最高的第一个) 写在模型中12345678910111213from datetime import datetimefrom test.helper import clientfrom mongoengine import *class BlogPost(Document): title = StringField() published_date = DateTimeField() meta = &#123; 'ordering': ['-published_date'] &#125; 写在查询语句中用order_by方法 只能用在单表查询中,不能用在aggregate中1users = Users.objects(**query).order_by(\"-role\") 在aggregate中使用sort排序12345678910111213141516171819202122232425pipeline_list = [ &#123;\"$sort\": &#123;'user_role': -1&#125;&#125;, &#123;'$lookup': &#123; 'from': 'shops', 'localField': 'shop', 'foreignField': '_id', 'as': 'staff_shop' &#125;&#125;, &#123;'$lookup': &#123; 'from': 'users', 'localField': 'user', 'foreignField': '_id', 'as': 'staff_user' &#125;&#125;, &#123;'$match': query_data&#125;, &#123;'$unwind': \"$staff_shop\"&#125;, &#123;'$unwind': \"$staff_user\"&#125;, &#123;'$project': &#123;'_id': True, 'created_timestamp': True, 'updated_timestamp': True, 'name': True, 'user_role': True, 'replenish_goods_permission': True, 'staff_shop.name': True, 'staff_shop.rates': True, 'staff_shop._id': True, 'staff_user.phone_number': True, 'staff_user.profile': True &#125;&#125; ]result = list(Model.objects().aggregate(*pipeline_list)) 继承 继承后的类并不会在数据库中创建新的集合,而是作为基类的属性存在.对于继承的集合我们要注意: 查询的时候既可以用基类查也可用子类查,但添加的时候只能用子类添加,不能用基类添加 12345678910111213141516171819from datetime import datetimefrom mongoengine import *from test.helper import clientclass Page(Document): title = StringField(max_length=200, required=True) meta = &#123;\"allow_inheritance\": True&#125;# Also stored in the collection named 'page'class DatedPage(Page): date = DateTimeField()if __name__ == '__main__': DatedPage(title='你好', date=datetime.now()).save() 数据库信息123456&#123; \"_id\": ObjectId(\"5f4b874d47ad45b9f7db6730\"), \"_cls\": \"Page.DatedPage\", \"title\": \"你好\", \"date\": ISODate(\"2020-08-30T19:02:37.057Z\")&#125; 自定义验证规则123456789101112131415161718192021from datetime import datetimefrom mongoengine import *from test.helper import clientclass Essay(Document): status = StringField(choices=('Published', 'Draft'), required=True) pub_date = DateTimeField() def clean(self): \"\"\"Ensures that only published essays have a `pub_date` and automatically sets `pub_date` if essays is published and `pub_date` is not set \"\"\" if self.status == 'Draft' and self.pub_date is not None: msg = 'Draft entries should not have a publication date.' raise ValidationError(msg) # Set the pub_date for published if not set already if self.status == 'Published' and self.pub_date is None: self.pub_date = datetime.now() 参考资料 mongoengine的文档类型和字段和排序和继承","tags":[{"name":"mongodb","slug":"mongodb","permalink":"http://saltci.xyz/tags/mongodb/"}],"categories":[{"name":"Database","slug":"Database","permalink":"http://saltci.xyz/categories/Database/"},{"name":"MongoDB","slug":"Database/MongoDB","permalink":"http://saltci.xyz/categories/Database/MongoDB/"}]},{"title":"Python操作redis","date":"2020-02-07T10:36:00.000Z","path":"Database/Redis/Python操作Redis/","text":"安装和使用安装redis1pip install redis redis连接12345678import redis# 加上decode_response=True，写入的键值对中的value为str类型，不加入这个参数则为字节类型client = redis.Redis(host='localhost',port=6379,decode_responses=True)client.set('name','eiheihei')# 取出键name对应的值print(client.get('name'))print(type(client.get('name'))) 连接池redis使用ConnectionPool来管理对一个redis server的所有连接，避免每次建立，释放连接的开销。默认每个Redis实例都会维护一个自己的连接池。可以直接建立一个连接池，然后作为Redis的参数，就可以实现多个Redis实例共享一个连接池。123456import redispool = redis.ConnectionPool(host='localhost',port=6379,decode_responses=True)client = redis.Redis(connection_pool=pool)client.set(\"gender\",\"male\")print(client.get('gender')) 字符串的创建，查询和修改set(name,value,ex=None,nx=False,xx=False) ex: 过期时间(秒) px: 过期时间(毫秒) nx: 如果设置为True，则只有name不存在的时，当前set操作才执行(新建) xx: 如果设置为True, 则只有name存在时，当前set操作才执行(修改) 1.ex，过期时间(秒)，这里过期时间是3秒，3秒后键food的值就变成None123456import redispool = redis.ConnectionPool(host='localhost',port=6379,decode_responses=True)client = redis.Redis(connection_pool=pool)client.set('food','mutton',ex=3) # key是food，value是mutton,将键值对存入redis缓存print(client.get('food')) 2.px，过期时间(毫秒)，这里过期时间是3毫秒，3毫秒后键food的值就变成None123456import redispool = redis.ConnectionPool(host='localhost',port=6379,decode_responses=True)client = redis.Redis(connection_pool=pool)client.set('food','mutton',px=3) # key是food，value是mutton,将键值对存入redis缓存print(client.get('food')) 3.nx,如果设置为True，则只有name不存在的时，当前set操作才执行(新建)12345678910import timeimport redispool = redis.ConnectionPool(host='localhost',port=6379,decode_responses=True)client = redis.Redis(connection_pool=pool)client.set('food','mutton',ex=2) # key是food，value是mutton,将键值对存入redis缓存time.sleep(3)# 如果键food不存在，返回True；如果键food存在，返回Noneprint(client.set('food','egg',nx=True)) # Trueprint(client.get('food')) # egg 4.xx,如果设置为True, 则只有name存在时，当前set操作才执行(修改)12print(client.set('food',\"egg\",xx=True)) # True,已经存在# 当键food已经存在，返回True;当键food不存在，返回None 列表的创建，查询和修改插入数据12345678910import redispool = redis.ConnectionPool(host='localhost',port=6379,decode_responses=True)client = redis.Redis(connection_pool=pool)client.lpush('example_list_python','python')# 插入多条数据方法一:client.rpush('example_list_python','life is short','first','second')# 插入多条数据方法二:datas = ['one','two','three','four']client.lpush('example_list_python',*datas) 读取数据123456789101112131415import redispool = redis.ConnectionPool(host='localhost',port=6379,decode_responses=True)client = redis.Redis(connection_pool=pool)# 1.查看列表长度print(client.llen('example_list_python'))# 2.获取列表中一定索引范围的数据print(client.lrange('example_list_python',0,-1))print(client.lrange('example_list_python',-4,-1))# 3.从左右侧弹出数据word_l = client.lpop('example_list_python')print(word_l,':',type(word_l))word_2 = client.rpop('example_list_python')print(word_2,':',type(word_2)) 修改数据12345678import redispool = redis.ConnectionPool(host='localhost',port=6379,decode_responses=True)client = redis.Redis(connection_pool=pool)# 查看列表里面所有数据client.lrange('example_list_python',0,-1)# 修改指定位置数据client.lset('example_list_python',4,'talk_is_cheap') 列表的应用简易分布式短信发送程序123456789101112131415161718192021222324import redisimport jsonclient = redis.Redis(host='xxx.xxx.xx.xx')while True: phone_info_bytes = client.lpop('phone_queue') if not phone_info_bytes: print('短信发送完毕！') break phone_info = json.loads(phone_info_bytes.decode()) retry_times = phone_info.get('retry_times', 0) phone_number = phone_info['phone_number'] result = send_sms(phone_number) if result: print(f'手机号：&#123;phone_number&#125; 短信发送成功！') continue if retry_times &gt;= 3: print(f'重试超过3次，放弃手机号：&#123;phone_number&#125;') continue next_phone_info = &#123;'phone_number': phone_number, 'retry_times': retry_times + 1&#125; client.rpush('phone_queue', json.dumps(next_phone_info)) 集合的创建，查找和修改插入数据12345678910import redispool = redis.ConnectionPool(host='localhost',port=6379,decode_responses=True)client = redis.Redis(connection_pool=pool)# 如果数据已经存在时添加，返回0；在数据不存在时添加，返回1client.sadd('example_set_python','hello')client.sadd('example_set_python',1,2.0,'three')datas = [9,8.0,'seven','VI']client.sadd('example_set_python',*datas) 读取数据1234567891011121314151617181920import redispool = redis.ConnectionPool(host='localhost',port=6379,decode_responses=True)client = redis.Redis(connection_pool=pool)# 查看集合中元素得个数count = client.scard('example_set_python')print(\"当前元素个数:\",count)# 使用spop从集合中获取1条数据msg = client.spop('example_set_python')print(msg)print('集合剩余元素个数&#123;&#125;'.format(client.scard('example_set_python')))print('--------------------')# 在python中spop没有'count'参数，因此只能获取一条数据，如果要获取多条数据可以使用For循环来实现for i in range(3): print(client.spop('example_set_python'))print('集合剩余元素个数&#123;&#125;'.format(client.scard('example_set_python')))# 获取集合中全部数据all_data = client.smembers('example_set_python')print(type(all_data) # &lt;class 'set'&gt; 删除数据123456789101112import redispool = redis.ConnectionPool(host='localhost',port=6379,decode_responses=True)client = redis.Redis(connection_pool=pool)datas = [1,2,'hello','python']result = client.sadd('example_set_python',*datas)print(client.smembers('example_set_python'))# 删除指定数据result = client.srem('example_set_python',\"hello\")print('-------------删除后-----------------')print(client.smembers('example_set_python')) 集合的运算1234567891011121314import redispool = redis.ConnectionPool(host='localhost',port=6379,decode_responses=True)client = redis.Redis(connection_pool=pool)# 添加数据set_datas_1 = [1,2,3,4,5]set_datas_2 = [4,5,6,7]client.sadd('set_python1',*set_datas_1)client.sadd('set_python2',*set_datas_2)print('集合的交集:',client.sinter('set_python1','set_python2'))print('集合的并集:',client.sunion('set_python1','set_python2'))print('set_python1对set_python2的差集:',client.sdiff('set_python1','set_python2'))print('set_python2对set_python1的差集:',client.sdiff('set_python2','set_python1')) 哈希表的功能和应用使用python向哈希表中添加数据 hset: 一次只能添加一个键值对,格式: client.hset(‘key’，’字段名’,’值’) hmset: 一次可以添加多个键值对,格式: client.hmset(‘key’,{‘字段名’:’值’,’字段名’:’值’})123456789101112import redisimport jsonclient = redis.Redis()client.hset(\"people_info\",'张小二',json.dumps(&#123;\"age\":17,\"salary\":100,\"address\":\"北京\"&#125;))other_people = &#123; \"王小三\":json.dumps(&#123;\"age\":20,\"salary\":9999,\"address\":\"四川\"&#125;), \"张小四\":json.dumps(&#123;\"age\":30,\"salary\":0,\"address\":\"山东\"&#125;)&#125;client.hmset('people_info',other_people) 使用python从哈希表中读取数据 hkeys: 用户获取所有字段的字段名，返回的数据时包含bytes型数据的列表 格式： filed_names = client.hkeys(‘哈希表名’) 1234567import redisclient = redis.Redis()field_names = client.hkeys('people_info')for name in field_names: print(name.decode()) hget: 获取一个字段的值，格式: client.hget(‘哈希表名’,’字段名’) hmget: 一次性获取多个字段的值，格式: client.hmget(‘哈希表名’,[‘字段名1’,’字段名2’,’字段名3’]) hgetall: 获取一个哈希表中的所有字段名的值，格式: client.hgetall(‘哈希表名’) 12345678910111213import redisclient = redis.Redis()# 获取一条数据info = client.hget('people_info','张小二')print(info.decode())# 获取多条数据info_list = hmget('people_info',['王小二','刘小五'])for info in info_list: print(info.decode())# 获取所有字段名和值all_info = hgetall('people_info')print(all_info) hget方法，无论时哈希表名不存在或者字段名不存在，都会返回None hmget方法，如果哈希表名不存在，则返回的列表所有元素都是None;如果哈希表中部分字段存在，部分字段不存在，则返回值列表中不存在的字段值表示为None hgetall方法返回的字典中，key,value都是bytes型的数据，因此查询里面的结果也要使用bytes型的数据 使用python判断哈希表中是否存在某个字段，并获取字段数量 1.判断一个哈希表中是否有某个字段 方法一: 获取这个字段的值，如果返回None，则这个字段就不存在 方法二: 使用hexists方法，如果字段存在返回True，否则返回False;如果key不存在，则直接返回False1234if client.hexists('people_info','张三'): print('存在张三这个字段')else: print('不存在张三这个字段') 2.查看一个哈希表中有多少个字段12num = client.hlen('people_info')print('people_info中一个有&#123;num&#125;个字段') 如果哈希表名存在，则返回字段数；如果不存在，则返回0 使用哈希表记录用户在线状态123456789101112131415161718192021222324252627import redisclient = redis.Redis()def set_online_status(user_id): ''' 当用户登录网站时调用这个函数。在Redis中，在名为user_online_status的哈希表中添加一个字段，字段名为用户账号，值为1 :param user_id: 用户账号 :reruan: None ''' client.hset('user_online_status',user_id,1)def set_offline_status(user_id): ''' 当用户登出这个网站时调用这个函数。从Redis中名为user_online_status的哈希表中删除一个字段，字段名为用户账号 :param user_id: 用户账号 :reruan: None ''' client.hdel('user_online_status',user_id)def check_online_status(user_id): ''' 检查用户是否在线。如果哈希表user_online_status中存在以用户账号为名的字段，则返回True，否则返回False :param user_id: 用户账号 :reruan: bool ''' return client.hexists('user_oneline_status',user_id) 发布消息/订阅频道 Redis的“发布订阅”模式是一种消息通信模式，实现了一对多的消息实时发布功能 实现一对多的消息发布1.使用字符串实现一对多的消息发布功能 定好一个字符串key,例如message 发送端使用字符串的set操作把新信息设置到这个key中 多个接收端不停的获取message的值，如果发现值变化了，则认为来了新的消息，接收并保存 发送端代码:1234567891011import redisimport datetimeimport jsonclient = redis.Redis()while True: message = input('请输入需要发布的消息:') now_time = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S') data = &#123;'message':message,'time':now_time&#125; client.set('message',json.dumps(data)) 接收端代码:1234567891011121314151617181920import redisimport timeimport jsonclient = redis.Redis()print('开始接收消息')last_message_time = Nonewhile True: data = client.get('message') if not data: time.sleep(1) continue info = json.dumps(data.decode()) message = info['message'] send_time = info['time'] if send_time == last_message_time: time.sleep(1) continue print(f'接到新消息:&#123;message&#125;,发送时间为:&#123;send_time&#125;') last_message_time = send_time 使用字符串的弊端: 接收端不知道发送端什么时候发布消息，因此必须持续不断检查Redis,浪费系统资源 由于轮询查询,所以消息有延迟 如果发送端在1秒内连续更新10条，则后一条会覆盖前一条，而接收每秒才能获取一次数据，必然会导致最多漏掉9条数据。要减少遗漏数量就需要增加轮询效率，进一步增大系统开销。 使用Redis的发布/订阅模式实现消息通信 发布/订阅模式是Redis自带的一对多消息通信模式。使用订阅/发布模式不仅可以解决字符串通信遇到的各种问题，而且代码更加简洁 发送端代码:1234567891011import redisimport jsonimport datetimeclient = redis.Redis()while True: message = input('请输入要发布的消息:') now_time = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S') data = &#123;'message':message,'time':now_time&#125; client.publish('pubinfo',json.dumps(data)) 接收端代码:1234567891011import redisimport jsonclient = redis.Redis()# 生成一个发布/订阅对象，并忽略订阅成功的消息listener = client.pubsub(ignore_subscrible_messages=True)# 订阅名为pubinfo的频道listener.subscribe('pubinfo')for message in listener.listen(): data = json.loads(message['data'].decode()) print(f'接收到的信息:&#123;data[\"message\"]&#125;,发送时间为:&#123;data[\"time\"]&#125;') 在Python中发布消息/订阅频道1.发布消息1234# 使用python向一个频道发布消息: client.publish('频道名','消息')import redisclient = redis.Redis()client.publish('pubinfo','message') 2.订阅频道 订阅频道设计的步骤稍微要多一些。首先需要生成一个发布/订阅对象，然后使用这个对象来订阅频道。订阅频道之后，循环从频道里面获取数据。 一个订阅实例只订阅一个频道1234567listener = client.pubsub()instener.subcribe('频道名')# instener.listen()是一个阻塞式的方法。程序运行到这里，如果频道里面没有数据，则程序会阻塞，知道频道里面有了新的信息，才会继续运行后面的代码for message in instener.listen(): # 第一次进入for循环，数据为&#123;'type':'subscribe','pattern':None,'channel':b'pubinfo','data':1&#125; # 这条消息表明订阅'pubinfo'成功,如果不想显示这一条内容，则在初始化发布订阅对象时，指定ignore_subscribe_messages=True print('每一条消息') 3.在一个发布订阅实例中订阅多个频道12345678910import redisimport jsonclient = redis.Redis()listener = client.pubsub(ignore_subscribe_messages=True)listener.subscribe('computer','math','shopping')for message in listener.listen(): channel = message['channel'].decode() data = message['data'].decode() print(f'频道:&#123;channel&#125;发送了一条消息:&#123;data&#125;') 注意事项: ‘发布/订阅’模式的工作工程就像收音机的广播一样，只有订阅到这个频道，才能收到消息，而之前的消息都丢失了。如:发送端先发送10条信息，在启动接收端，而接收端是没有办法收到先发送的10条信息的 可以有非常多的接收端同时订阅一个频道。一旦这个频道有消息发布，所有接收端都会收到信息。 有序集合 有序集合(sorted set)是Redis的一个数据结构。有序集合里面的数据跟集合一样，也是不能重复的，但是每一个元素又关联了一个分数，根据这个分数可以对元素进行排序，分数可以重复。 实现排行榜功能 分别用MongoDB和Redis的有序集合来实现排行榜功能。对比传统数据库的排序功能，寻找有序集合实现排序功能的优点 1.使用传统数据库实现排行榜123import pymongohandler = pymongo.MongoClient().chapter_9.rank_dataresult = handler.find(&#123;&#125;).sort('score',-1) 使用数据库排序的弊端： 排行榜会实时更新，数据每一次变化都需要排序，会对数据库性能造成影响 频繁更新数据，导致数据库性能下降 数据量太大时，排序时间缓慢 对被排序字段添加索引会占更多空间 2.使用有序集合进行排序123456789101112131415import pymongoimport redis# 直接把mongodb中的数据导入redis中名为rank的有序集合handler = pymongo.MongoClient('mongodb://root:iamsuperuser@localhost').chapter_9.rank_dataclient = redis.Redis()rows = handler.find(&#123;&#125;,&#123;'_id':0&#125;)for row in rows: client.zadd('rank',row['user_id'],row['score'])# 显示某个特定用户的排名position = client.zrevrank('rank',10017)print(f'用户:10017排名为&#123;position + 1&#125;')# 显示全部用户的排名rank = client.zervrank('rank',0,10000,withscores=True) 使用Python读写有序集合1.向有序集合添加数据 方法一: client.zadd(&#39;有序集合名&#39;,&#39;值1&#39;,&#39;评分1&#39;,&#39;值2&#39;,&#39;评分2&#39;) 方法二: client.zadd(&#39;有序集合&#39;,值1=评分1,值2=评分2)1234567name1 = '王小二'name2 = '张三'# 值与评分都可以用变量，也可以直接写client.zadd('age_rank',name1,18,name2,26,'小明',10)# 只能写值，不能用变量，但评分可以使用变量client.zadd('age_rank',王小二=18,张三=26,小明=10) 2.修改评分 修改评分使用的方法是zincrby,格式: client.zincrby(&#39;有序集合名&#39;,值,该变量)12client.zincrby('age_rank','王小二',3)client.zincrby('age_rank','小明',-0.5) 3.对有序集合元素基于评分范围进行排序 根据评分范围进行排序，使用的方法分别是zrangebyscore和zrevrangebyscore,这两个方法用法完全相同，差别在于: zrangebyscore根据评分从小到大的顺序排序 zrevrangebyscore根据评分从大到小的顺序排序 格式： client.zrangebyscore(&#39;有序集合名&#39;,评分上限，评分下限，结果切片起始位置，结果数量，withscores=False) client.arevrangebyscore(&#39;有序集合名&#39;,评分上限，评分下限，结果切片起始位置，结果数量，withscores=False) 如果withscores为False返回的结果是直接排序好的值；如果withscores为True，则返回的列表里面的元素是元组，元组第一个元素是值，第二个元素是评分 12# 对积分在10-100范围内的人员进行倒序排序，并返回前3条数据client.zrevrangebyscore('rank',100,10,0,3) 4.对有序集合基于位置进行排序 基于位置范围进行排序，用到的方法名为:zrange和zrevrange zrange对评分按照从小到大的顺序排序 zrevrange对评分按照从大到小的顺序排序 格式: client.zrange(‘有序集合名’,开始位置(含),结束位置(含),desc=False,withsocres=False) client.zrevrange(‘有序集合名’,开始位置(含),结束位置(含),withscores=False) zrange()方法 12345# 如果使用的是zrange方法，则位置0是评分最小的元素，# 当然开始位置和结束位置也可以是负数，表示从后往前数，例如开始位置-4,结束位置-1result = client.zrange('rank',0,4,withscores=True)for index,one in enumerate(result): print(f'用户id:&#123;one[0].decode()&#125;,积分:&#123;one[1]&#125;,排行榜第&#123;index + 1&#125;') zrevrange()方法 使用zrevrange方法，位置0是最大的元素,如果开始位置写0，结束位置写4，最取最大的5个元素如果开始位置取-4，结束位置取-1，则取最小的4个元素，且Score高的在前 123rank_100_1000 = client.zrevrange('rank',0,4,withscores=True)for index,one in enumerate(rank_100_1000): print(f'用户id:&#123;one[0].decode()&#125;,积分:&#123;one[1]&#125;,排行榜第&#123;index + 1&#125;') 5.根据值查询排名，根据值查询评分 使用zrank和zrevrank方法，可以查询一个值在有序列表中的排名1234# client.zrank('有序列表名','值'),如果值存在，则返回值的排名，最小值为0；如果值不存在则返回Noneclient.zrank('rank','张三')# client.zrevrank('有序列表名','值'),如果值存在，则返回值的排名，最大值为0；如果值不存在则返回Noneclient.zrevrank('rank','张三') 6.其它常用方法 zcard: 查询有序集合里面一共有多少个值，如果有序集合不存在返回0,格式:zcard(&#39;有序集合名&#39;) zcount: 查询在某个评分范围内有多少个值，格式:zcount(&#39;有序集合名&#39;,评分上限，评分下限) 参考资料 使用Python来操作redis用法详解","tags":[{"name":"redis","slug":"redis","permalink":"http://saltci.xyz/tags/redis/"}],"categories":[{"name":"Database","slug":"Database","permalink":"http://saltci.xyz/categories/Database/"},{"name":"Redis","slug":"Database/Redis","permalink":"http://saltci.xyz/categories/Database/Redis/"}]},{"title":"Redis快速上手","date":"2020-02-07T04:36:00.000Z","path":"Database/Redis/Redis快速上手/","text":"Redis快速入门Redis安装和使用安装和启动1234# ubuntu安装redis-serversudo apt-get install redis-server# 服务端启动sudo /etc/init.d/redis-server start [,status,stop,restart] 客户端连接12345redis-cli -h &lt;ip地址&gt; -p &lt;端口&gt;# 默认连接本机的6379端口redis-cli127.0.0.1:6379&gt;pingPONG 设置连接密码12345678# 修改配置文件中 requirepass &lt;password&gt;requirepass &lt;yourpassword&gt;# linux 重启服务sudo /etc/init.d/redis-server restart# window 重启服务redis-server.exe redis.windows.conf# 测试连接redis -h 127.0.0.1 -p 6379 -a 123456 设置远程连接12345678# 修改bind 127.0.0.1,注释掉bind即允许所有ip访问bind 14.68.225.22 127.0.0.1# 修改保护模式protected-mode no# 重启redis服务sudo /etc/init.d/redis-server restart# 测试连接redis -h 14.68.225.22 -p 6379 -a 123456 禁用危险命令 Redis中默认开启了一些非常高权限的一些命令，使用这些命令，轻则清空Redis，重则写入挖矿木马甚至是SSH key公钥，从而控制服务器通过修改Redis配置文件，可以对一些危险命令进行改名或者禁用，从而降低安全风险 1.打开Redis配置文件，添加如下内容:123456789rename-command CONFIG &quot;&quot;rename-command FLUSHDB sdfaksdfjkasdrename-command FLUSHALL SDFKSDDrename-command PEXPIRE OKASETTWrename-command SHUTDOWN &quot;&quot;rename-command BGREWRITEAOF SEWERWEFSDFrename-command BGSAVE ASDFPEWErename-command SAVE ASDFKLEWErename-command DEBUG &quot;&quot; 2.如果把命令重命名为空字符串，表示禁用这个命令。 通用命令，适用于所有数据类型 select &lt;number&gt;: 切换库(number的值0-15之间的数字) keys *: 查看所有键,如keys user*(查看user开头的键) TYPE key: 键类型 exists key: 键是否存在 del key: 删除键 rename key newkey: 重命名键 flushdb: 清除当前库中所有数据(慎用) flushall: 清除所有库中所有数据(慎用) 字符串的创建，查询和修改字符串(Strings)是Redis的基本数据结构之一，它由key和value两部分组成。 创建字符串语法:set key value key可以是数字，大小写字母，下划线或者中文 value可以是任意内容1set give_me_a_word OK 查询字符串1keys * 读取字符串如果获取一个不存在的key，则会返回(nil)1get give_me_a_word 修改key里面的值12345678# 如果Redis不存在这个key则创建，存在这个key使用新的值覆盖旧值set user_data New# 使用nx参数，当key不存在时创建，当key存在时放弃操作set user_data abc NX# 给字符串的末尾加上其他字符串append user_data abc# 如果值的内容有空格，需要用引号包起来set user_data \"word1 word2 word3\" 数值操作123456789101112# 1.整数操作# 让key里的数字加1incr focus# 让key里的数字减1decr focus# 让key的数字增加100incrby focus 100# 让key里的数字减少100decrby focus 100# 2.浮点数操作incrbyfloat key step string命令汇总123456789101112131415161718192021222324252627282930313233# 1.字符串操作set key valueset key value nxget key# 同时设置多个key-valuemset key1 value1 key2 value2 key3 value3# 同时获取多个key-valuemget key1 key2 key3# 设置过期时间,过了日期就自动销毁,ex秒 px毫秒set key value ex seconds# 查询key的过期时间还剩多少秒ttl key # 没有设置过期时间返回-1;key已经过期返回-2# 获取长度strlen key# 2.数字操作incrdecrincrbydecrbyincrbyfloat key number# 3.设置过期时间的两种方式# 方式一set key value ex 3# 方式二set key valueexpire key 5 # 秒pexpire key 5 # 毫秒# 4.查看存活时间ttl key# 5.删除过期persist key# 返回旧值并设置新值(如果键不存在，就创建并赋值)getset key value 列表的创建，查询和修改列表（List）是Redis中的另一种数据结构。 插入数据列表分左右两个方向，所以可以从左右两侧插入。12345678910# 1.从列表左侧插入数据lpush example_list hello# 如果有多个value，使用空格隔开lpush example_list how are you# 如果value本身有空格，使用引号包起来lpush example_list \"are you ok\" fine thank you# 2.从列表右侧插入数据rpush example_list_right 你好rpush example_list_right 请问贵姓 免贵姓王rpush example_list_right \"幸会 幸会\" \"久仰 久仰\" 查看数据123456789101112131415161718# 1.查看列表的长度llen key# 2.根据索引查看数据,0代表最左边的数据，-1代表最右边的数据# 查看索引为6的数据lrange example_list 6 6# 查看索引从2(包括2)到5（包括5）的数据lrange example_list 2 5# 3.查看列表所有数据# 不要贸然列出列表里面的所有数据，如果一个列表内有上百万条数据，贸然列出所有数据可能会导致大量数据输出瞬间耗尽系统IO资源lrange key 0 -1# 4.弹出数据,在弹出数据同时，被弹出的这个数据会从列表中删除# 从左边弹出数据lpop key# 从右边弹出数据rpop key 修改数据1lset key index 新的值 删除多余的信息123# 格式: ltrim key &lt;起始位置&gt; &lt;截至位置&gt;# 使用ltrim命令删除多余的信息，只保留列表最右侧的20条信息ltrim chat_list -1 -20 集合的创建，查询和修改Redis的集合与列表一样可以存放很多数据，但不同之处在于:集合里面的数据不能重复，也没有顺序 插入数据1234# sadd key value1 value2 value3sadd example_set hellosadd example_set 1 2.0 threesadd example_set \"thank you\" \"you are welcome\" 读取数据1234567891011121314# 1.查询集合里面元素的数量:scard keyscard example_set# 2.从集合中获取数据,spop命令会随机获取集合中的数据:spop key count# 获取一条数据后，这一条数据就会从集合中删除spop example_setspop example_set 3spop example_set 1000# 3.获取集合中所有数据：smembers key,该命令不会删除数据，但如果集合中数据量极大，慎用smembers example_set# 4.判断集合中是否包含某个元素# sadd命令在遇到数据已存在时会返回0，数据不存在则把数据插入之后返回1# 单纯检查数据是否在集合中，可以使用sismember: sismember key value# 如果数据存在返回1，反之则返回0sismember example_set 2 删除数据12# 使用srem命令，从集合中删除指定数据:srem key value1 value2 value3srem example_set \"thank you\" 集合的交集1234# 在redis中，求集合交集使用的命令为sinter:sinter key1 key2 key3sadd set_1 1, 2 python three C 三sadd set_2 9 8.0 七 VI python 2sinter set_1 set_2 # 2 python 集合的并集1234# 在redis中，求集合并集使用的命令是sunion: sunion key1 key2 key3sadd set_4 9 8.0 七 VII python 2sadd set_3 1, 2 python three C 三sunion set_3 set_4 集合的差集1234# 在redis中，求集合的差集使用的命令是sdiff: sdiff key1 key2 key3sadd set_6 9 8.0 七 VII python 2sadd set_5 1, 2 python three C 三sdiff set_5 set_6 哈希表的功能和应用向哈希表中添加内容12hset people_info 赵老六 '&#123;\"age\":10,\"salary\":1000,\"address\":\"北京\"&#125;'hmset book_info 论语 32 中庸 48 大学 50 向哈希表中读取数据 从哈希表中读取数据，分别对应的命令是: hkeys, hget, hmget, hgetall,它们的格式如下:1234hkeys 哈希表名hget 哈希表名 字段名hmget 哈希表名 字段名1 字段名2 字段名3hgetall 哈希表名 判断字段是否存在和获取字段数量 判断字段是否存在使用命令hexists, 获取字段数量使用关键字heln,它们的格式如下：12hexists 哈希表名 字段名hlen 哈希表名 执行hexists时，如果字段存在，则返回1；如果字段不存在，则返回0. 发布消息/订阅频道发布消息1publish computer 人工智能新突破 订阅频道12# subscribe 频道名1 频道名2subscribe computer math 订阅之后，一旦被订阅的频道有新的消息发布，订阅端就会收到消息 每条消息都会对应redis-cli中的3条返回消息: 第一条是信息类，第二条是频道名，第三条是被发布的内容 有序集合 有序集合(sorted set)是Redis的一个数据结构。有序集合里面的数据跟集合一样，也是不能重复的，但是每一个元素又关联了一个分数，根据这个分数可以对元素进行排序，分数可以重复。 添加数据1zadd 有序集合名 评分1 值1 评分2 值2 评分n 值n 修改评分1zincrby 有序集合名 修改的分数 值 基于评分范围排序，基于位置范围排序12345# 基于评分范围排序# WITHSCORES可以省略，省略之后，只有值没有分# 如果不需要对结果进行切片，则LIMIT 切片开始位置 结果数量也可以省略zrangebyscore 有序列表 评分下限 评分上限 WITHSCORES LIMIT 切片开始位置 结果数量zrevrangebyscore 有序列表 评分下限 评分上限 WITHSCORES LIMIT 切片开始位置 结果数量 查询值得排名，查询值得评分123456# 查询值得排名zrank 有序集合名 值zrevrank 有序集合名 值# 查询值得评分zscore 有序集合名 值 其它常用命令1234# 查询有序集合中元素得个数zcard 有序集合名# 查询评分范围内得元素个数zcount 有序集合名 积分下限 积分上限","tags":[{"name":"redis","slug":"redis","permalink":"http://saltci.xyz/tags/redis/"}],"categories":[{"name":"Database","slug":"Database","permalink":"http://saltci.xyz/categories/Database/"},{"name":"Redis","slug":"Database/Redis","permalink":"http://saltci.xyz/categories/Database/Redis/"}]},{"title":"Python内置函数","date":"2020-02-06T13:11:42.000Z","path":"Python/Python内置函数/","text":"isinstance函数描述isinstance()函数来判断一个对象是否是已知的类型，类似于type() 语法1234isinstance(object,classinfo)# object: 实例对象# classinfo: 可以是直接或间接类名，基本类型或者由他们组成的元组# 返回值: 如果对象的类型与参数二的类型相同在则返回True，否则返回False 实例1234a = 2isinstance(a,int) # Trueisinstance(a,str) # Flaseisinstance(a,(str,int,list)) # 是元组中的其中一个返回True isinstance()与type()的区别 type()不会认为子类是一种父类类型，不考虑继承关系 isinstance()会认为子类是一种父类类型，考虑继承关系 如果判断两个类型是否相同推荐使用isinstance() 12345678class A: passclass B(A): passisinstance(A(),A) # Truetype(A()) == A # Trueisinstance(B(),A) # Truetype(B()) == A # Flase issubclass()函数描述issubclass()方法用于判断参数class是否是类型参数calssinfo的子类。 语法1234issubclass(class,classinfo)# class:类# classinfo:类# 返回值: 如果class是classinfo的子类返回True,否则返回False 实例123456class A: passclass B(A): passprint(issubclass(B,A)) # True getattr()函数描述getattr()函数用于返回一个对象属性值。 语法12345getattr(object,name[, default])# object: 对象# name: 字符串，对象属性# default: 默认返回值，如果不提供该参数，在没有对应属性时，将触发AttributeError# 返回值: 返回对象属性值 实例123456class A: bar = 1a = A()getattr(a,'bar') # 获取属性bar的值getattr(a,'bar2') # 属性bar2不存在，触发AttributeError异常getarrr(a,'bar2',3) # 属性bar2不存在，但设置了默认值，返回默认值3 enumerare()函数描述enumerate()函数用于将一个可便利的数据对象组合成一个索引序列，同时列出数据和数据下标，一般用在for循环中 语法1234enumerate(sequence,[start=0])# sequence: 一个序列，迭代器或其他支持迭代对象# start: 下表起始位置# 返回值: 返回enumerate对象 实例12345678910test_list = ['This','is','a','test']for index,item in enumerate(test_list) print(index,item)&gt;&gt;&gt;1 This2 is3 a4 test 利用enumerate()统计文件行数1234row_count = 0for index, line in enumerate(open('generate_data.py','r',encoding='utf-8')): row_count += 1print(row_count) all()函数描述all()函数用于判断给定的可迭代参数iterable中的元素是否都为True，如果是返回True，否则返回False。元素除了是0，空，None外都算True,函数等价于12345def all(iterable): for element in iterable: if not element: return False return False 语法1234all(iterable)# iterable: 元组或列表# 返回值: 如果iterable里面所有元素不为0，'',False或者iterable为空，all(iterable)返回True,否则返回False# 注意: 空元组，空列表返回True 实例12345all([\"a\",\"b\",\"c\",\"d\"]) # Trueall(['a', 'b', '', 'd']) # Falseall([0,1,2,3]) # Falseall([]) # Trueall(()) # True any()函数描述any()函数用于判断给定的可迭代参数iterable是否全为False，如果有一个为True，则返回True。元素除了是0,空，False外都算True,函数等价于:12345def any(iterable): for element in iterable: if element: return True return False 语法123any(iterable)# iterable: 元组或列表# 返回值: 如果都为空，0,False则返回False,否则返回True 实例12345any(['a', 'b', 'c', 'd']) # Trueany(['a', 'b', '', 'd']) # Trueany([0, '', False]) # Falseany([]) # Falseany(()) # False","tags":[{"name":"Python","slug":"Python","permalink":"http://saltci.xyz/tags/Python/"}],"categories":[{"name":"Python","slug":"Python","permalink":"http://saltci.xyz/categories/Python/"}]},{"title":"MongoDB常用命令","date":"2020-02-04T04:36:00.000Z","path":"Database/MongoDB/MongDB常用命令/","text":"MongoDB基础操作常用命令1234567891011121314# 1.切换/创建数据库use &lt;your db&gt;# 2.查询所有数据库show dbs# 3.删除当前使用数据库db.dropDatabase()# 4.查看当前使用的的数据库db.getName();# 5.查看当前db状态db.stats()# 6.查看当前db版本db.version()# 7.查看当前db的链接的机器地址db.getMongo() 插入数据1234567# 1.插入单条数据db.getCollection('test').insertOne(&#123;\"name\":\"张三\",\"age\":17&#125;)# 2.批量插入数据db.getCollection('test').insertMany([ &#123;\"name\":\"张三\",\"age\":17&#125;, &#123;\"name\":\"李四\",\"age\":18&#125;]) 注: 每一条数据被插入MongoDB后都会被自动添加”_id”字段，_id读作ObjectId,它是由时间，机器码，进程PID和自增计数器构成。 查询数据1234567891011121314151617181920212223242526272829# 1.查询所有数据db.getCollection('test').find()# 2.查询特定数据(如果有多个字段，多个字段需要同时满足)db.getCollection('test').find(&#123;\"字段1\":\"值1\",\"字段2\":\"值2\"&#125;)# 3.查询范围值数据db.getCollection('test').find(&#123;\"age\":&#123;\"$lte\":25,\"$gte\":50&#125;&#125;)# 4.限定返回哪些字段# 格式:db.getCollection('test').find('用于过滤记录的字典','用于限定字段的字典')db.getCollection('test').find(&#123;&#125;,&#123;'address':0,\"age\":0&#125;) # 如果值为0：全部字段中剔除值为0的字段并返回# 如果值为1：只返回值为1的这些字段# '_id'比较特殊，除非限定字段的字典把\"_id\"值设为0，否则默认返回# 如果不考虑'_id'则限定字段的字典里面的值非0即1，不能混用# 5.查询满足要求的数据有多少条db.getCollection('test').find(&#123;\"age\":&#123;\"$gt\":25&#125;&#125;).count()# 6.限定返回结果db.getCollection('test').find().limit(4)# 7.对查询结果进行排序# 字段的值为-1表示倒序，为1表示正序db.getCollection('test').find(&#123;\"age\":&#123;\"$gt\":21&#125;&#125;).sort(&#123;\"age\":-1&#125;)# 8.对数据进行偏移，比如偏移2，就忽略前两个元素，得到第三个及以后的元素db.getCollection('test').find().sort(&#123;\"age\":-1&#125;).skip(2) 常用操作符: $gt :大于 $gte :大于等于 $lt :小于 $lte :小于等于 $ne :不等于 $in : 匹配数组中的任一值 $nin：不匹配数组中的任一值 $regex: 匹配正则表达式 $exists: 属性是否存在 $type: 类型判断 $mod: 数字模操作 $test: 文本查询 $where: 高级条件查询 修改数据语法: db.getCollection(&#39;test&#39;).updateMany({&quot;字段&quot;:&quot;值&quot;},{&quot;$set&quot;:{&quot;字段1&quot;:&quot;新的值1&quot;,&quot;字段2&quot;:&quot;新的值2&quot;}}) 第一个参数同find的第一个参数，用来寻找所有需要被更新的记录 第二个参数是一个字典，key为$set,它的值是另外一个字典，这个字典里指定要被修改的字段名的新的值 1234db.getCollection('test').updateMany( &#123;\"name\":\"张三\"&#125;, &#123;\"$set\":&#123;\"address\":\"苏州\"&#125;&#125;) 删除数据1234# 为了防止误删除，一般做法是先查询要删除的数据，然后再将查询的数据删除db.getCollection('test').find(&#123;\"name\":\"张三\"&#125;)# 将find修改为deleteManydb.getCollection('test').deleteMany(&#123;\"name\":\"张三\"&#125;) 注：一般实际工作中会使用”加删除”，即增加一个deleted字段,如果值为0表示没有删除，如果值为1表示已经被删除 MongoDB高级操作使用正则表达式查询1db.getCollection('test').find(&#123;\"name\":&#123;\"$regex\":\"^r\"&#125;&#125;) AND和OR操作隐式AND操作12# 查询所有age大于20并且sex为\"男\"的数据db.getCollection('test').find(&#123;\"age\":&#123;\"$gt\":20&#125;,\"sex\":\"男\"&#125;) 显示AND操作12345# 显示AND操作语法: collection.find(&#123;\"$and\":[字典1,字典2,字典3,...,字典n]&#125;)# 查询所有年龄大于20并且sex为\"男\"的数据db.getCollection('test').find(&#123; \"$and\":[&#123;\"age\":&#123;\"$gt\":20&#125;&#125;,&#123;\"sex\":\"男\"&#125;]&#125;) 显示AND和隐式AND操作混合12345# 查询所有年龄大于20，性别为男，并且ID小于10的数据db.getCollection('test').find(&#123; \"id\":&#123;\"$lt\":10&#125;, \"$and\":[&#123;\"age\":&#123;\"$gt\":20&#125;&#125;,&#123;\"sex\":\"男\"&#125;]&#125;) OR操作OR操作会自动按顺序去检查每一个条件，遵循短路原则：只要前面的条件满足了，那后面的条件就直接跳过。123456# 语法: db.getcollection('test').find(&#123;\"$or\":[字典1,字典2,字典3,...,字典n]&#125;)db.getCollection('test').find(&#123; \"$or\":[ &#123;\"age\":&#123;\"$gt\":28&#125;&#125;, &#123;\"salary\":&#123;\"$gt\":9900&#125;&#125;]&#125;) 不能写成隐式的AND操作所有的隐式操作都可以改写成显示AND操作，但反之则不行。1234567891011db.getCollection('test').find(&#123; \"$and\":[ &#123;\"$or\":[ &#123;\"age\":&#123;\"$gt\":28&#125;&#125;, &#123;\"salary\":&#123;\"$gt\":9900&#125;&#125; ]&#125;, &#123;\"$or\":[ &#123;\"sex\":\"男\"&#125;, &#123;\"id\":&#123;\"$lt\":20&#125;&#125; ]&#125;]&#125;) 查询子文档或数组中的数据认识嵌入式文档123456&#123; \"content\":\"五星好评!\", \"create_time\":\"2020-01-01\", \"user\":&#123;\"name\"：\"张三\",\"user_id\":100,\"following\":1,\"followed\":100&#125;, \"comments\":100&#125; 上面这个数据中，user称为嵌入式文档，user下面的字段被称为嵌套字段。 查询嵌套字段需要使用点号指定具体字段名:嵌入式文档名.嵌套字段名 使用点号定位嵌套字段1234# 查询user中的子字段user_id为102的数据db.getCollection('test').find(&#123;\"user.user_id\":102&#125;)# 查询所有followed大于10的数据db.getCollection('test').find(&#123;\"user.followed\":&#123;\"$gt\":10&#125;&#125;) 返回嵌套字段中特定内容1234db.getCollection('test').find( &#123;\"user.followed\":&#123;\"$gt\":10&#125;&#125;, &#123;\"_id\":0,\"user.name\":1,\"user.user_id\":1&#125;&#125;) 认识数组字段12345&#123; \"name\":\"衬衣\", \"size\":[\"S\",\"M\",\"L\",\"XL\"], \"price\":[100,200,300,800]&#125; 查询数组包含不包含数据1234# 1.查询所有\"size\"包含\"M\"的数据db.getCollection('test').find(\"size\":\"M\")# 2.查询数组不包含数据db.getCollection('test').find(\"size\":&#123;\"$ne\":\"M\"&#125;) 查询数组中至少有一个元素在某个范围内1db.getCollection('test').find(&#123;\"price\":&#123;\"$lt\":300,\"$gte\":200&#125;&#125;) 根据数组长度查询数据12# 查询所有price字段长度为2的记录db.getCollection('test').find(&#123;\"price\":&#123;\"$size\":2&#125;&#125;) $size只能查询具体某一个长度的数组，不能查询长度大于或小于某个值的数组 根据数组索引查询数据12# 查询所有size中的第一个数据为S的记录db.getCollection('test').find(&#123;\"size.0\":\"S\"&#125;) 根据数组索引比较数据的大小12# 查询price第一个数据大于500的所有记录db.getCollection('test').find(&#123;\"price.0\":&#123;\"$gt\":500&#125;&#125;) 聚合查询聚合的基本语法1collection.aggregate([阶段1,阶段2,阶段3,...,阶段N]) 聚合操作可以有0个，1个或多个阶段 如果为0，则它的作用的find一样 如果聚合有至少一个阶段，那么每个阶段都是一个字典。不同阶段负责不同的事情，每个阶段都有一个关键字。有专门负责筛选数据的$match，有专门负责字段相关阶段的$project等。 筛选数据1234# 查询所有age大于28或者sex为男的记录db.getCollection('test').aggregate([ &#123;\"$match\":&#123;\"$or\":[&#123;\"age\":&#123;\"$gt\":28&#125;&#125;,&#123;\"sex\":\"男\"&#125;]&#125;&#125;]) 抽取嵌套字段123db.getCollection('test').aggregate([ &#123;\"$project\":&#123;\"name\":\"$user.name\",\"user_id\":\"$user.user_id\"&#125;&#125;]) 处理字段特殊值 添加一个字段，字段的值是数字1 添加一个字段，字段的值是一个普通字符串，但是以$开头1234db.getCollection('test').aggregate([ &#123;\"$match\":&#123;\"age\":&#123;\"$gt\":28&#125;&#125;&#125;, &#123;\"$project\":&#123;\"_id\":0,\"hello\":&#123;\"$literal\":\"$normalstring\"&#125;,\"abcd\":&#123;\"$literal\":1&#125;&#125;&#125;]) 分组操作分组操作对应的关键词是$group,它的作用是根据给出的字段key，把所有key的值相同的记录放在一起运算，这些运算包含:求和($sum),计算平均数($avg),最大值($max),最小值($min)等。 分组操作阶段去重1234567# 分组操作去重语法：collection.aggregate([&#123;\"$group\":&#123;\"_id\":\"$被去重的字段名\"&#125;&#125;])# 1.使用分组操作对name字段进行去重db.getCollection('test').aggregate([ &#123;\"$group\":&#123;\"_id\":\"$name\"&#125;&#125;])# 2.使用distinct函数去重db.getCollection('test').distinct('name') distinct函数和分组操作去重的区别: distinct函数在mongodb去重之后会返回一个数组，在Python中去重之后会返回一个列表 分组操作去重之后会返回记录 分组操作并计算统计值1234567891011db.getCollection('test').aggregate([ &#123;\"$group\": &#123; \"_id\":\"$name\", \"max_score\":&#123;\"$max\":\"$score\"&#125;, \"min_score\":&#123;\"$min\":\"$score\"&#125;, \"sum_score\":&#123;\"$sum\":\"$score\"&#125;, \"averge_score\":&#123;\"$avg\":\"$score\"&#125;, &#125; &#125;]) $sum的值可以为1，这样查询语句就变成统计每个分组内有多少条记录 $sum和$avg的值对应的字段的值应该是数字，强行使用非数字字段，$sum返回0,$avg返回null 字符串可以比较大小，所以$max和$min可以正常应用到字符串型字段 去重并选择最新/最老数据123456789db.getCollection('test').aggregate([ &#123; \"$group\":&#123; \"_id\":\"$name\", \"date\":&#123;\"$last\":\"$date\"&#125;, \"score\":&#123;\"$last\":\"$score\"&#125; &#125; &#125;]) $last表示取最后一条数据 将$last替换为$first即取第一条数据 在mongodb中，老数据先插入，新数据后插入，所以每一组最后一条数据就是最新插入的数据 拆分数组1234db.getCollection('test').aggregate([ &#123;\"$unwind\":\"$size\"&#125;, &#123;\"$unwind\":\"$price\"&#125;]) 联集合查询相当于SQL中的联表查询。在某些情况下，一些相关的数据需要保存到多个集合中，然后使用某一个字段进行关联 数据集1234567891011121314# 用户集合(weiboi_user)&#123; \"id\":1001, \"name\":\"张三\", \"register_date\":\"2018-06-09\", \"age\":17, \"work\":\"学生\"&#125;# 微博集合(weibo_post)&#123; \"user_id\":1001, \"content\":\"你好世界\", \"post_time\":\"2018-06-11 12:23:12\"&#125; 联集合查询语法 相等匹配 12345678910主集合.aggregate([ &#123; \"$lookup\":&#123; \"from\":\"被查集合名\", \"localField\":\"主集合字段\", \"foreignField\":\"被查集合字段\", \"as\":\"保存查询结果的字段名\" &#125; &#125;]) 条件和不相关子查询:在两个集合之间执行不相关的子查询以及允许除单个相等match之外的其他连接条件 12345678910&#123; \"$lookup\":&#123; \"from\":\"被查集合名\", \"let\":&#123;&lt;var1&gt;:&lt;expression&gt;&#125;, \"pipeline\":[ &lt;pipeline to excute on the collection to join&gt; ], \"as\":\"output array field\" &#125;&#125; let: 指定要在pipeline阶段中使用的变量 pipeline: 指定要在已连接结合上运行的管道。 联集合查询1.同时知道微博内容和发微博用户的名字与职业。1234567891011121314151617db.getCollection('weibo_post').aggregate([ &#123; \"$lookup\":&#123; \"from\":\"weibo_user\", \"localField\":\"user_id\", \"foreignField\":\"id\", \"as\":\"user_info\" &#125; &#125;, &#123;\"$unwind\":\"$user_info\"&#125;, &#123;\"$project\":&#123; \"content\":1, \"post_time\":1, \"name\":\"$user_info.name\", \"work\":\"$user_info.work\" &#125;&#125;]) 2.查询名为张三用户发送的微博123456789101112131415161718db.getCollection('weibo_user').aggregate([ &#123;\"$match\":&#123;\"name\":\"张三\"&#125;&#125;, &#123; \"$lookup\":&#123; \"from\":\"weibo_post\", \"localField\":\"id\", \"foreignField\":\"user_id\", \"as\":\"weibo_info\" &#125; &#125;, &#123;\"$unwind\":\"$weibo_info\"&#125;, &#123;\"$project\":&#123; \"name\":1, \"work\":1, \"content\":\"$weibo_info.content\", \"post_time\":\"$weibo_info.post_time\" &#125;&#125;]) 参考资料","tags":[{"name":"mongodb","slug":"mongodb","permalink":"http://saltci.xyz/tags/mongodb/"}],"categories":[{"name":"Database","slug":"Database","permalink":"http://saltci.xyz/categories/Database/"},{"name":"MongoDB","slug":"Database/MongoDB","permalink":"http://saltci.xyz/categories/Database/MongoDB/"}]},{"title":"Python操作MongoDB","date":"2020-02-04T04:36:00.000Z","path":"Database/MongoDB/Python操作MongoDB/","text":"使用pymongo操作MongoDB数据库连接数据库安装pymongo1pip install pymongo 连接数据库12345678# 1.如果mongodb运行在本地，且没有修改端口或者添加用户名和密码，则初始化MongoClient实例不需要带参数from pymongo import MongoClientclient = MongoClient()# 2.如果mongodb运行在远程服务器上，则需要使用URL来指定链接地址# 格式：mongodb://&lt;username&gt;:&lt;password&gt;@&lt;ip地址或域名&gt;:&lt;端口&gt;/数据库名client = MongoClient(\"mongodb://username:123456@45.76.110.210:27019\")# 3.如果没有设置权限认证则不需要用户名和密码client = MongoClient(\"mongodb://45.76.110.210:27109\") 连接库与集合 方法一： 1234from pymongo import MongoClientclient = MongoClient()database = client.test_dbcollection = database.test_collection 方法二: 123456from pymongo import MongoClientclient = MongoClient()db_name = \"test_db\"collection_name = \"test_collection\"database = client[db_name]clllection = database[collection_name] pymongo基本操作mongo命令与pymongo方法对照表 MongoDB命令 PyMongo命令 insertOne insert_one insertMany insert_many find find updateOne update_one updateMany update_many deleteOne delete_one deleteMany delete_many 插入数据1234567891011from pymongo import MongoClientclient = MongoClient()database = client[\"test_db\"]collection = database[\"test_collection\"]# 批量插入数据collection.insert_many([ &#123;\"name\":\"张三\",\"age\":12&#125;, &#123;\"name\":\"李四\",\"age\":15&#125;])# 插入单条数据collection.insert_one(&#123;\"name\":\"李四\",\"age\":15&#125;) 查询数据1234567891011from pymongo import MongoClientclient = MongoClient()database = client[\"test_db\"]collection = database[\"test_collection\"]rows = collection.find(&#123; \"age\":&#123;\"$lt\":25,\"$gt\":21&#125;, \"name\":&#123;\"$ne\":\"张三\"&#125;&#125;)for row in rows: print(row) 更新数据12345678910from pymongo import MongoClientclient = MongoClient()database = client[\"test_db\"]collection = database[\"test_collection\"]# 更新多条数据collection.update_many( &#123;\"name\":\"张三\"&#125;, &#123;\"$set\":&#123;\"address\":\"美国\",\"age\":80&#125;&#125;) 使用$set只更新字典内存在的字段，如果不用$set则会把之前的数据全部用字典替换掉，原本存在的其它字段会删除 更新操作支持upsert参数，如果该参数存在则更新，不存在则创建 如果使用了upsert参数，则$set的值应该包含每个字段，否则被插入的内容只有被更新的这几个字段 删除数据1collection.delete_many(&#123;\"age\":0&#125;) python实现mongoDB的regex查询12345678910import pymongo# 连接mongodbhandler = pymongo.MongoClient().test_db.test_collectionquery_bds = &#123;\"name\":&#123;\"$regex\":\"^R\"&#125;&#125;rows = handler.find(query_bds)for row in rows: print(row) Python实现MongoDB的AND和OR操作12345678910111213141516171819import pymongo# 连接mongodbhandler = pymongo.MongoClient().test_db.test_collectionrows = handler.find(&#123; \"$and\":[ &#123;\"$or\":[ &#123;\"age\":&#123;\"$gt\":28&#125;&#125;, &#123;\"salary\":&#123;\"$gt\":9900&#125;&#125; ]&#125;, &#123;\"$or\":[ &#123;\"sex\":\"男\"&#125;, &#123;\"id\":&#123;\"$lt\":20&#125;&#125; ]&#125;]&#125;)for row in rows: print(row) Python操作嵌入式文档和数组字段123456789import pymongo# 连接mongodbhandler = pymongo.MongoClient().test_db.test_collectionrows1 = handler.find(&#123;\"size.0\":\"M\"&#125;)rows2 = handler.find(&#123;\"price\":&#123;\"$lt\":300,\"$gte\":200&#125;&#125;)rows3 = handler.find(&#123;\"price\":&#123;\"$size\":2&#125;&#125;)rows4 = handler.find(&#123;\"price.0\":&#123;\"$gt\":500&#125;&#125;) 使用python执行聚合操作1234567891011121314151617181920212223242526import pymongo# 连接mongodbhandler = pymongo.MongoClient().test_db.test_collectionpipe = [ &#123;\"$match\":&#123;\"name\":\"张三\"&#125;&#125;, &#123; \"$lookup\":&#123; \"from\":\"weibo_post\", \"localField\":\"id\", \"foreignField\":\"user_id\", \"as\":\"weibo_info\" &#125; &#125;, &#123;\"$unwind\":\"$weibo_info\"&#125;, &#123;\"$project\":&#123; \"name\":1, \"work\":1, \"content\":\"$weibo_info.content\", \"post_time\":\"$weibo_info.post_time\"&#125;&#125;]rows = handler.aggregate(pipe)for row in rows: print(row) MongoDB与Python不通用的操作空值 MongoDB中空值写作null,Python中空值写作None 布尔值 MongoDB中真为true,假为false,首字母小写； Python中真为True，假为False，首字母大写 排序参数 MongoDB中sort()命令接收一个字典，key是排序的字段名，值为1或-1 Python中sort()方法接收两个参数，第一个参数为字段名，第二个参数为-1或者1 查询ID MongoDB中可以根据_id的值来查询文档,查询语句如下： 1db.getCollection('test').find(&#123;\"_id\":ObjectID(\"5e37e51fe222645d0e3272f3\")&#125;) Python中需要从bson库中导入ObjectID,代码如下： 123456789from pymongo import MongoClientfrom bson import ObjectIDclient = MongoClient()database = client[\"test_db\"]collection = database[\"test_collection\"]rows = collection.find(&#123;\"_id\":ObjectID(\"5e37e51fe222645d0e3272f3\")&#125;, ,&#123;\"_id\":0&#125;) MongoDB优化和安全建议常见问题 使用Pymongodb操作数据时，凡是涉及写的操作(比如insert,update)，需要进行异常处理。 提高MongoDB读写性能批量插入与逐条插入数据，比较性能差异 1.生成初始数据1234567891011121314151617181920212223242526272829303132import csvimport randomfirst_word_in_name = '赵钱孙李周吴郑王冯陈褚卫蒋沈韩杨朱秦尤许何吕施张孔曹严华金魏陶姜戚谢邹喻柏水窦章云苏潘葛奚范彭郎'second_word_in_name = '天地玄黄宇宙洪荒日月盈昃辰宿列张寒来暑往秋收冬藏闰余成岁律吕调阳云腾致雨露结为霜金生丽水玉出昆冈剑号巨阙'third_word_in_name = '对酒当歌人生几何譬如朝露去日苦多慨当以慷忧思难忘何以解忧唯有杜康青青子衿悠悠我心但为君故沉吟至今'print(len(first_word_in_name),len(second_word_in_name),len(third_word_in_name))work_number = 1people_list = []for first in first_word_in_name: for second in second_word_in_name: for third in third_word_in_name: name = first + second + third age = random.randint(0, 100) salary = random.randint(10000, 20000) phone_number = '1' for n in range(10): phone_number += str(random.randint(0, 9)) people_list.append(&#123;'work_number': work_number, 'name': name, 'age': str(age), 'salary': str(salary), 'phone': phone_number&#125;) work_number += 1with open('people_info.csv', 'w', encoding='utf-8-sig',newline='') as f: writer = csv.DictWriter(f, fieldnames=['work_number', 'name', 'age', 'salary', 'phone']) writer.writeheader() writer.writerows(people_list) 2.逐行插入数据的时间12345678910111213141516import csvimport timeimport pymongowith open('people_info.csv', encoding='utf-8') as f: reader = csv.DictReader(f) people_info_list = [x for x in reader]handler = pymongo.MongoClient().chapter_8.one_by_onestart_time = time.time()for info in people_info_list: handler.insert_one(info)end_time = time.time()print('逐条插入数据，耗时：', end_time - start_time) 逐条插入数据，耗时： 28.835277795791626 3.批量插入数据1234567891011121314import csvimport timeimport pymongowith open('people_info.csv', encoding='utf-8') as f: reader = csv.DictReader(f) people_info_list = [x for x in reader]handler = pymongo.MongoClient().chapter_8.batchstart_time = time.time()handler.insert_many(people_info_list)end_time = time.time()print('批量插入数据，耗时：', end_time - start_time) 批量插入数据，耗时： 2.1189966201782227 4.如何正确的批量插入数据 仅仅是本地的MongoDB数据库，批量插入数据的性能远远超过逐条插入数据性能。如果使用的是远程数据库，那么网络IO导致的时间消耗估计更大。 从Redis里面读数据，再插入到MongoDB中：1234567891011121314151617import redisimport jsonimport pymongoclient = redis.Redis()handler = pymongo.MongoClient().chatper_8.people_infopeople_info_list = []while True: people_info_json = client.lpop('people_info') if people_info_json: people_info = json.loads(people_info_json.decode()) people_info_list.append(people_info) else: breakhandler.insert_many(people_info_list) 如果Redis中的数据量非常大，全部转换成字典以后超过系统内存了，怎么办？ 如果Redis中的数据临时暂停添加，过一会再添加，会怎么样？ 假设Redis中有100 000 000条数据，读取到99 999 999条数据断电了，会怎么样？ 5.批量一次性插入数据 如果已经明确知道redis中的数据就是全部数据，虽然多，但是不会继续增加新的数据，那么代码可以修改为如下：123456789101112131415161718192021222324import redisimport jsonimport pymongoclient = redis.Redis()handler = pymongo.MongoClient().chatper_8.people_infopeople_info_list = []while True: people_info_json = client.lpop('people_info') if people_info_json: people_info = json.loads(people_info_json.decode()) people_info_list.append(people_info) # 如果列表中的数据超过1000条就先插入数据库 if len(people_info_list) &gt;= 1000: handler.insert_many(people_info_list) people_info_list = [] else: break# 最后一轮可能凑不够1000条数据，所以还需要看看是否需要再次插入if people_info_list: handler.insert_many(people_info_list) 6.批量插入持续性数据 如果Redis中的数据是持续性数据，则会有新的数据源源不断被加入到Redis中，每次添加的时间间隔不定，代码可以修改为如下：1234567891011121314151617181920212223242526import redisimport jsonimport timeimport pymongoclient = redis.Redis()handler = pymongo.MongoClient().chatper_8.people_infopeople_info_list = []# 计数变量，只要请求Redis的次数为1000的倍数，那就批量插入数据库，这样保证people_info_list的数据最多等待100秒就会被插入数据库get_count = 0while True: people_info_json = client.lpop('people_info') if people_info_json: people_info = json.loads(people_info_json.decode()) people_info_list.append(people_info) if len(people_info_list) &gt;= 1000: handler.insert_many(people_info_list) people_info_list = [] else: if people_info_list and get_count % 1000 == 0: handler.insert_many(people_info_list) people_info_list = [] time.sleep(0.1) # 在本次发现redis为空的情况下，暂停0.1秒，这样做可以显著降低CPU的占用 get_count += 1 插入与更新数据，比较性能差异 更新操作（特别是逐条更新）比较浪费时间，因为它实际上包含了“查询”和“修改”两个步骤。与“插入”不一样，某些情况下数据的“更新”没办法实现批量操作，必须逐条更新。 1.逐条更新数据123456789101112import timeimport pymongostart_time = time.time()handler = pymongo.MongoClient().chapter_8.one_by_onefor row in handler.find(&#123;&#125;, &#123;'salary': 1&#125;): salary = int(row['salary']) new_salary = salary + 100 handler.update_one(&#123;'_id': row['_id']&#125;, &#123;'$set': &#123;'salary': str(new_salary)&#125;&#125;)end_time = time.time()print('逐条更新数据，耗时：', end_time - start_time) 逐条更新数据，耗时： 35.01171922683716 2.用插入数据代替更新数据 对于必须逐条更新大量数据的情况，也可以使用插入代替更新来提高性能。基本逻辑是：把数据插入到另外一个集合，然后删除原来的集合，再把新集合名改名为原来的集合1234567891011121314151617import timeimport pymongostart_time = time.time()db = pymongo.MongoClient().chapter_8batch = db.batchnew_collection = db.update_by_insertnew_people_info_list = []for row in batch.find(): salary = int(row['salary']) new_salary = salary + 100 row['salary'] = str(new_salary) new_people_info_list.append(row)new_collection.insert_many(new_people_info_list)end_time = time.time()print('使用插入代替更新，耗时：', end_time - start_time) 使用插入代替更新，耗时： 2.155980110168457 使用索引提高查询速度 索引是一种特殊的数据结构，它使用了能够快速遍历的形式记录了集合中数据的位置。如果不使用索引，则每一次查询数据都会遍历整个集合；如果使用了索引，则数据库会直接根据索引快速找到需要的内容 创建索引123456import pymongohandler = pymongo.MongoClient().chapter8.one_by_one# 创建索引，background为False，在创建索引时，这个集合就不能被查询和写入，但是速度快# background为True，在创建索引时速度会慢一些，但是不影响其他程序读写这个集合handler.create_index(\"salary\",background=True) 索引是以空间换时间。集合中的数据越多，索引占用的硬盘空间就越多。所以对必要的字段添加索引，不要对所有字段都添加索引 _id默认自带索引，不需要添加 引入redis,以降低mongodb读取频率 12345678def init(): all_title = mongo_handler.disinct('title') redis_client.sadd('news_title',*all_title)def need_insert_news(news_title): if redis_client.sadd('news_title',news_title) == 1: return True return False 增添适当冗余信息，以提高查询速度在插入数据库时，添加一个特殊字段special，满足条件就是True,不满足条件就是False.通过special这个字段来提高查找效率. 提高MongoDB的安全性配置权限管理机制 为了增强MongoDB的安全性，需要配置基于角色的访问控制机制（Role-Based Access Control） 1.创建管理员用户 管理员的作用是创建其他用户。管理员用户本身不能对数据库进行控制。 创建管理员账户 123456use admindb.createUser(&#123; user:\"admin\", pwd:\"123456789\", roles:[&#123;role:\"userAdminAnyDatabase\",db:\"admin\"&#125;]&#125;) 修改配置文件,启用权限管理功能 12security: authorization: enabled 重启MongoDB数据库 123# 执行mongo命令，发现虽然能够连上数据库，但是已经不能执行常规操作了# 使用以下命令登录mongomongo -u 'admin' -p '123456' --authenticationDatabase 'admin' 2.创建普通用户 管理员账户没有权限操作普通数据库。要操作普通数据库，还需要创建普通用户。 创建一个对chaprter_8数据库有读写权限，对chapter_4只有读权限的普通用户。123456789use chapter_8db.createUser(&#123; user:\"kingname\", pwd:\"123456\", roles:[&#123;role:'readWrite',db:'chapter_8'&#125;, &#123;role:'read',db:'chapter_4'&#125;]&#125;) 3.创建能操作数据库的超级管理员 管理员账户能创建其他用户，看似权限很大，但不能访问任何一个数据库。所以如果有必要，还需要创建一个能对所有数据库都有全部权限的用户。 创建能操作数据库的管理员12345678use admindb.createUser(&#123; user:\"root\", pwd:\"123456\", roles:['root']&#125;) 开放外网访问 修改mongodb配置文件之后重启数据库12# 编辑文件/etc/mongodb.confbind_ip:0.0.0.0 连接数据库12mongo --host localhost:27017 -u root -p --authenticationDatabase adminmongo 127.0.0.1:27017/admin -u root -p password 数据库导出和恢复12# 恢复数据库mongorestore --host localhost:27017 --username test --password ************ --gzip --archive=xxx.gz --db xxx 参数说明","tags":[{"name":"Python,mongodb","slug":"Python-mongodb","permalink":"http://saltci.xyz/tags/Python-mongodb/"}],"categories":[{"name":"Database","slug":"Database","permalink":"http://saltci.xyz/categories/Database/"},{"name":"MongoDB","slug":"Database/MongoDB","permalink":"http://saltci.xyz/categories/Database/MongoDB/"}]},{"title":"shell脚本编程","date":"2020-02-01T14:00:00.000Z","path":"Linux/shell脚本编程/","text":"第一个shell脚本编写新建扩展名为.sh的文件,文件内容如下:12#!/bin/bashecho \"hello world!\" 正文的第一行#!/bin/bash告诉shell这个脚本需要什么解释器来执行 运行脚本 运行shell脚本有两种办法： 作为可执行程序: 12chmod +x test.sh./test.sh 作为解释器参数: 1/bin/bash test.sh 变量自定义变量123456#!/bin/bash# 定义变量your_name='test'# 使用变量echo $your_nameecho $&#123;your_name&#125; 注： 变量名和等号之间不能有空格 shell的变量属于弱类型 变量名：数字，下划线，字母组成，不能以数字开始 预设变量 示例一：1234#!/bin/bashecho $USER $UID $PWD $PATHsleep 100 &amp;echo $! PATH变量: 存储命令搜索路径 $$: 当前进程的进程号 $!: 前一个后台进程的进程号 示例二：1234567891011#!/bin/bashecho $1echo $2echo $*echo $## chmod +x test.sh# ./test.sh a 11 c op# a# 11# a 11 c op# 4 $1: 脚本的第一个参数 $2: 脚本的第二个参数 $*: 所有参数的值 $#: 所有参数的个数 $?: 返回上一个命令的执行状态(0表示正确,非0表示不正确) 示例三: read命令读取用户输入 12345#!/bin/bashread -p 请输入用户名: usernameread -p 请输入密码: passworduseradd $usernameecho \"$username:$password\" | chpasswd 等待用户输入 read -p “提示信息:” 变量名 read -t 2 -p ”提示信息:“ 变量名（限制2秒钟之内必须输入值） 字符串字符串是shell编程中最常见的数据类型，字符串可以用单引号，也可以用双引号，也可以不用引号。 单引号1str = 'this is a string' 单引号字符串限制: 单引号中任何字符都会原样输出，单引号字符中的变量是无效的 单引号字符中不能出现单引号(对单引号使用转义符后也不行) 双引号12your_name='test'str=\"Hello, I know you are \\\"$&#123;your_name&#125;\\\"! \\n\" 双引号内可以有变量 双引号内可以出现转义字符 字符串操作字符串拼接123you_name=\"test\"greeting=\"hello, $&#123;you_name&#125; !\"echo greeting 获取字符串长度12string=\"abcd\"echo $&#123;#string&#125; # 4 提取子字符串12string=\"alibaba is a great company\"echo $&#123;string:1:4&#125; # 输出 liba 查找子字符串12string=\"alibaba is a great company\"echo `expr index \"$string\" is` # 输出3 条件判断判断的语法格式1234# 判断语句括号两边必须有空格[ 判断语句 ]# A &amp;&amp; B 仅当A成功时才执行B # A || B 仅当A失败时才执行B 字符判断 [ A == A ] 判断相等 [ A != B ] 判断不相等 [ -z $变量 ] 判断是否为空12345678#!/bin/bashread -p \"请输入用户名:\" username[ -z $username ] &amp;&amp; exitread -p \"请输入密码:\" passwd[ -z $passwd ] &amp;&amp; exit# useradd $username# echo \"$username:$passwd\" | chpasswd 数字比较 -eq :等于(equal) -ne :不等于(not equal) -gt :大于(greater than) -ge :大于等于(great or equal) -lt :小于(less than) -le :小于等于(less or equal)1[ 3 -eq 3 ] &amp;&amp; echo Y || echo N 文件和目录 [ -e 文件或目录 ] :是否存在 [ -f 文件 ] :存在且为文件 [ -d 目录 ] :存在且为目录 [ -r 文件或目录 ] :判断是否可读 [ -w 文件或目录 ] :判断文件是否可写 [ -x 文件或目录 ] :判断文件是否可执行123[ -e /etc/passwd ] &amp;&amp; echo Y || echo N[ -f /etc/passwd ] &amp;&amp; echo Y || echo N[ -d /etc/passwd ] &amp;&amp; echo Y || echo N if语句单分支 双分支 多分支 推荐阅读 Linux运维之道 参考资料 Shell脚本编程30分钟入门","tags":[{"name":"linux","slug":"linux","permalink":"http://saltci.xyz/tags/linux/"}],"categories":[{"name":"Linux","slug":"Linux","permalink":"http://saltci.xyz/categories/Linux/"}]},{"title":"pandas","date":"2020-01-22T07:44:42.000Z","path":"Python/data_analysis/pandas/","text":"pandas概述 pandas是一种Python数据分析利器,是一个开源的数据分析包,最初是应用于金融数据分析工具而开发,因此pandas为时间序列提供了很好的支持. pandas导入12from pandas import Series,DataFrameimport pandas as pd pandas基本数据结构 Series: 一种类似于一维数组的对象,由一组数据(各种numpy数据类型)以及一组与之相关的数据标签(即索引)组成.仅由一组数据也可产生简单的Series对象.注意:Series中的索引值是可以重复的. DataFrame: 一个表格型的数据结构,包含有一组有序的列,每列可以实不同的值类型(数值,字符串,布尔型等),DataFrame即有行索引也有列索引,可以被看作是由Series组成的字典.","tags":[{"name":"Python","slug":"Python","permalink":"http://saltci.xyz/tags/Python/"}],"categories":[{"name":"Python","slug":"Python","permalink":"http://saltci.xyz/categories/Python/"},{"name":"data_analysis","slug":"Python/data-analysis","permalink":"http://saltci.xyz/categories/Python/data-analysis/"}]},{"title":"wget命令","date":"2020-01-22T03:43:52.000Z","path":"Linux/wget命令/","text":"wget命令使用实例实例1:使用wget下载单个文件1$wget http://www.minjieren.com/wordpress-3.1-zh_CN.zip 实例2：使用wget -O下载并以不同的文件名保存1$wget -O wordpress.zip http://www.minjieren.com/download.aspx?id=1080 wget默认会以最后一个符合”/”的后面的字符来命令，对于动态链接的下载通常文件名会不正确。 实例3：使用wget –limit -rate限速下载1$wget --limit-rate=300k http://www.minjieren.com/wordpress-3.1-zh_CN.zip 实例4：使用wget -c断点续传1$wget -c http://www.minjieren.com/wordpress-3.1-zh_CN.zip 实例5：使用wget -b后台下载123$wget -b http://www.minjieren.com/wordpress-3.1-zh_CN.zipContinuing in background, pid 1840.Output will be written to 'wget-log'. 对于下载非常大的文件的时候，我们可以使用参数-b进行后台下载。 你可以使用以下命令来察看下载进度:1$tail -f wget-log 实例6：伪装代理名称下载1wget --user-agent=\"Mozilla/5.0 (Windows; U; Windows NT 6.1; en-US) AppleWebKit/534.16 (KHTML, like Gecko) Chrome/10.0.648.204 Safari/534.16\" http://www.minjieren.com/wordpress-3.1-zh_CN.zip 实例7：使用wget -i下载多个文件1234567$cat &gt; filelist.txturl1url2url3url4$wget -i filelist.txt 实例8：使用wget –mirror镜像网站1$wget --mirror -p --convert-links -P ./LOCAL URL 下载整个网站到本地 –miror:开户镜像下载 -p:下载所有为了html页面显示正常的文件 -convert-links:下载后，转换成本地的链接 -P ./LOCAL：保存所有文件和目录到本地指定目录 实例9: 使用wget -r -A下载指定格式文件1$wget -r -A.pdf url 可以在以下情况使用该功能： 下载一个网站的所有图片 下载一个网站的所有视频 下载一个网站的所有PDF文件 实例10：使用wget FTP下载12$wget ftp-url$wget --ftp-user=USERNAME --ftp-password=PASSWORD url 可以使用wget来完成ftp链接的下载 使用wget匿名ftp下载：wget ftp-url 使用wget用户名和密码认证的ftp下载:wget –ftp-user=USERNAME –ftp-password=PASSWORD url 参考资料 Linux Tools Quick Tutorial","tags":[{"name":"linux","slug":"linux","permalink":"http://saltci.xyz/tags/linux/"}],"categories":[{"name":"Linux","slug":"Linux","permalink":"http://saltci.xyz/categories/Linux/"}]},{"title":"jupyter_notebook常用指南","date":"2020-01-21T05:42:42.000Z","path":"Python/data_analysis/jupyter_notebook/","text":"常用快捷键1shift + enter 运行 参考资料 -","tags":[{"name":"Python","slug":"Python","permalink":"http://saltci.xyz/tags/Python/"}],"categories":[{"name":"Python","slug":"Python","permalink":"http://saltci.xyz/categories/Python/"},{"name":"data_analysis","slug":"Python/data-analysis","permalink":"http://saltci.xyz/categories/Python/data-analysis/"}]},{"title":"numpy","date":"2020-01-21T05:11:42.000Z","path":"Python/data_analysis/numpy/","text":"numpy简介 numpy是以矩阵为基础的数学计算模块,纯数学存储和处理大型矩阵,是Python进行科学计算的基础 numpy是其它数据分析及机器学习库的底层库 numpy基于标准C语言实现,运行效率充分优化 numpy基础ndarray数组创建np.array:接收一个普通python序列,并将其转换为ndarray123456789101112131415import numpy as npnp.array([1,2,3])# array([1, 2, 3])# 用元组创建np.array((1,2,3))# array([1, 2, 3])# 多维数组np.array( [1,2,3,4], [5,6,7,8])# array([[1, 2, 3, 4],# [5, 6, 7, 8]]) np.zeros(数组元素个数,dtype=’类型’):创建指定长度或者形状的全零数组1234567import numpy as npnp.zeros((3,3))# array([[0., 0., 0.],# [0., 0., 0.],# [0., 0., 0.]])np.zeros(10,dtype='int32')# array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0]) np.ones(数组元素个数,dtype=’类型’):创建指定长度或者形状的全1数组12345import numpy as npnp.ones((3,3),dtype='int32')# array([[1, 1, 1],# [1, 1, 1],# [1, 1, 1]]) np.empty(shape,dtype=’float’,order=’C’):创建指定形状和dtype的未初始化数组12345import numpy as npnp.empty((3,3))# array([[1., 1., 1.],# [1., 1., 1.],# [1., 1., 1.]]) np.arange(起始值,终止值,步长)123import numpy as npnp.arange(0,9,2)# array([1, 3, 5, 7]) np.linspace():生成等差数列123import numpy as npnp.linspace(1,10,5)# array([ 1. , 3.25, 5.5 , 7.75, 10. ]) np.logspace():生成等比数列123456import numpy as npnp.logspace(0,2,5)# array([ 1. , 3.16227766, 10. , 31.6227766 ,# 100. ])np.logspace(0,2,5,base=2)# array([1. , 1.41421356, 2. , 2.82842712, 4. ]) np.random12345678910111213141516import numpy as npnp.random.random((3,3))# array([[0.80835636, 0.29228671, 0.53821761],# [0.62159912, 0.92745278, 0.7099457 ],# [0.37325982, 0.31742215, 0.71386294]])np.random.randint(1,9,size=(3,3))# array([[3, 6, 6],# [2, 2, 8],# [8, 5, 8]])np.random.randn(3,3)# array([[ 1.00618523, -0.44050643, 0.08845778],# [-0.31211208, 0.9232979 , -1.19750328],# [-0.40024231, 1.50681083, -0.85000261]])np.random.rand(9)# array([0.38573675, 0.86529341, 0.07380751, 0.65909173, 0.60161683,# 0.19712216, 0.09138534, 0.09792456, 0.92164262]) ndarray对象属性参考资料 菜鸟教程 Numpy numpy中文网","tags":[{"name":"Python","slug":"Python","permalink":"http://saltci.xyz/tags/Python/"}],"categories":[{"name":"Python","slug":"Python","permalink":"http://saltci.xyz/categories/Python/"},{"name":"data_analysis","slug":"Python/data-analysis","permalink":"http://saltci.xyz/categories/Python/data-analysis/"}]},{"title":"lsof命令","date":"2020-01-21T02:48:52.000Z","path":"Linux/lsof命令/","text":"lsof命令lsof(list open files)是一个查看当前系统文件的工具.在Linux环境下,任何事物都以文件的形式存在,通过文件不仅仅可以访问常规数据,还可以访问网络连接和硬件.如传输控制协议(TCP)和用户数据报协议(UDP)套接字等,系统后台都为该应用程序分配了一个文件描述符,该文件描述符提供了大量关于这个应用程序本身的信息. lsof可以打开的文件可以是: 普通文件 目录 网络文件系统的文件 字符和设备文件 (函数)共享库 管道,命名管道 符号链接 网络文件(如:NFS file,网络Socket,unix域名socket) 等等 lsof命令参数 -a 列出打开文件存在的进程 -c&lt;进程名&gt; 列出指定进程所打开的文件 -g 列出GID号进程详情 -d&lt;文件号&gt; 列出占用该文件号的进程 +d&lt;目录&gt; 列出目录下被打开的文件 +D&lt;目录&gt; 递归列出目录下被打开的文件 -n&lt;目录&gt; 列出使用NFS的文件 -i&lt;条件&gt; 列出符合条件的进程。（4、6、协议、:端口、 @ip ） -p&lt;进程号&gt; 列出指定进程号所打开的文件 -u 列出UID号进程详情 -h 显示帮助信息 -v 显示版本信息 lsof使用实例实例1: 无任何参数12345$lsof | moreCOMMAND PID TID USER FD TYPE DEVICE SIZE/OFF NODE NAMEsystemd 1 root cwd DIR 253,1 4096 2 /systemd 1 root rtd DIR 253,1 4096 2 / 说明: lsof输出各列信息的意义如下: COMMAND:进程的名称 PID:进程标识符 USER:进程所有者 FD:文件描述符,应用程序通过文件描述符识别该文件,如cwd,txt等 12345678910111213141516171819202122232425262728293031323334（1）cwd：表示current work dirctory，即：应用程序的当前工作目录，这是该应用程序启动的目录，除非它本身对这个目录进行更改（2）txt ：该类型的文件是程序代码，如应用程序二进制文件本身或共享库，如上列表中显示的 /sbin/init 程序（3）lnn：library references (AIX);（4）er：FD information error (see NAME column);（5）jld：jail directory (FreeBSD);（6）ltx：shared library text (code and data);（7）mxx ：hex memory-mapped type number xx.（8）m86：DOS Merge mapped file;（9）mem：memory-mapped file;（10）mmap：memory-mapped device;（11）pd：parent directory;（12）rtd：root directory;（13）tr：kernel trace file (OpenBSD);（14）v86 VP/ix mapped file;（15）0：表示标准输入（16）1：表示标准输出（17）2：表示标准错误一般在标准输出、标准错误、标准输入后还跟着文件状态模式：r、w、u等（1）u：表示该文件被打开并处于读取/写入模式（2）r：表示该文件被打开并处于只读模式（3）w：表示该文件被打开并处于（4）空格：表示该文件的状态模式为unknow，且没有锁定（5）-：表示该文件的状态模式为unknow，且被锁定同时在文件状态模式后面，还跟着相关的锁（1）N：for a Solaris NFS lock of unknown type;（2）r：for read lock on part of the file;（3）R：for a read lock on the entire file;（4）w：for a write lock on part of the file;（文件的部分写锁）（5）W：for a write lock on the entire file;（整个文件的写锁）（6）u：for a read and write lock of any length;（7）U：for a lock of unknown type;（8）x：for an SCO OpenServer Xenix lock on part of the file;（9）X：for an SCO OpenServer Xenix lock on the entire file;（10）space：if there is no lock. TYPE:文件类型,如DIR,REG等,常见的文件类型: 123456（1）DIR：表示目录（2）CHR：表示字符类型（3）BLK：块设备类型（4）UNIX： UNIX 域套接字（5）FIFO：先进先出 (FIFO) 队列（6）IPv4：网际协议 (IP) 套接字 DEVICE:指定磁盘的名称 SIZE:文件的大小 NODE:索引节点(文件在磁盘上的标识) NAME:打开文件的确切名称 实例2: 查看某个文件相关的进程123456$lsof /bin/bashCOMMAND PID USER FD TYPE DEVICE SIZE/OFF NODE NAMEmysqld_sa 2169 root txt REG 253,0 938736 4587562 /bin/bashksmtuned 2334 root txt REG 253,0 938736 4587562 /bin/bashbash 20121 root txt REG 253,0 938736 4587562 /bin/bash 实例3: 列出某个用户打开的文件信息1$lsof -u &lt;username&gt; 实例4: 列出某个程序进程所打开的文件信息12$lsof -c mysql$lsof | grep mysql 实例5:列出谁在使用某个端口1$lsof -i:3306 参考资料 lsof 一切皆文件","tags":[{"name":"linux","slug":"linux","permalink":"http://saltci.xyz/tags/linux/"}],"categories":[{"name":"Linux","slug":"Linux","permalink":"http://saltci.xyz/categories/Linux/"}]},{"title":"time和datetime模块","date":"2020-01-19T13:11:42.000Z","path":"Python/time和datetime模块/","text":"Python提供了多种多样对时间日期的处理方式，平常使用最多的就是time和datetime这两个模块。 timedatetime参考资料 time模块Python官方文档 datetime模块Python官方文档","tags":[{"name":"Python","slug":"Python","permalink":"http://saltci.xyz/tags/Python/"}],"categories":[{"name":"Python","slug":"Python","permalink":"http://saltci.xyz/categories/Python/"}]},{"title":"crontab命令","date":"2020-01-16T05:49:52.000Z","path":"Linux/crontab命令/","text":"crontab命令 crontab格式说明 编辑crontab 1crontab -e 查看计划任务 1crontab -l crontab使用实例 实例1: 每1分钟执行一次myCommand 1* * * * * * myCommand 实例2:每小时的第3和第15分钟执行 13,15 * * * * myCommand 实例3:在上午8点到11点的第3和第15分钟执行 13,15 8-11 * * * myCommand 实例4:每隔两天的上午8点到11点的第3和第15分钟执行 13,15 8-11 */2 * * myCommand 实例5:每周一上午8点到11点的第3和第15分钟执行 13,15 8-11 * * 1 myCommand 实例6:每晚的21:30重启smb 130 21 * * * /etc/init.d/smb restart 在重启时运行任务 1234# 在每次重启时都运行一条命令@reboot python /home/pi/myscript.py# 希望命令仅仅在后台运行@reboot python /home/pi/myscript.py &amp; 晚上11点到早上7点之间，每隔一小时重启smb 10 23-7 * * * /etc/init.d/smb restart crontab验证工具 crontab在线工具 ATools在线crontab校验 参考资料 crontab 定时任务 树莓派计划任务的配置方法","tags":[{"name":"linux","slug":"linux","permalink":"http://saltci.xyz/tags/linux/"}],"categories":[{"name":"Linux","slug":"Linux","permalink":"http://saltci.xyz/categories/Linux/"}]},{"title":"YAML","date":"2020-01-15T06:43:05.000Z","path":"DevOps/YAML/","text":"参考资料","tags":[],"categories":[{"name":"DevOps","slug":"DevOps","permalink":"http://saltci.xyz/categories/DevOps/"}]},{"title":"Kubernetes基本概念与使用","date":"2020-01-14T16:04:03.000Z","path":"DevOps/Kubernetes/Kubernetes基本概念/","text":"Kubernetes基本概念 Master: Master节点是Kubernetes集群的控制节点,负责整个集群的管理和控制,包含以下组件: kube-apiserver：集群控制的入口，提供HTTP REST 服务 kube-controller-manager：Kubernetes 集群中所有资源对象的自动化控制中心 kube-scheduler：负责 Pod 的调度 Node: Kubernetes集群中的工作节点,可以是物理机,也可以是虚拟机。Node 上的工作负载由 Master 节点分配，工作负载主要是运行容器应用。每个Node节点包含以下组件: container runtime(docker或rkt) kubelet:负责Pod的创建,启动,监控,重启,销毁等工作,同时与Master节点协作,实现集群管理的基本功能 kube-proxy:实现Kubernetes Service的通信和负载均衡 Pod: Pod 是一组紧密关联的容器集合，它们共享 PID、IPC、Network 和 UTS namespace， 是 Kubernetes 最基本的部署调度单元。 Label: 标签是可以附加到资源的任意键值对,用以选择具有该标签的资源。标签选择器不仅可以组织pod,也可以组织所有其它的Kubernetes资源。 Label Selector: 标签选择器根据资源的以下条件来选择资源: 包含(或不包含)使用特定键的标签 包含具有特定键和值的标签 包含具有特定键的标签,但其值与我们指定的不同 Namespace: 命名空间是对一组资源和对象进行抽象的集合,常用于隔离资源或隔离用户;常见的pods,services,replication controllers和deployments等都是属于某一个namespace(默认是default),而node,persistentVolumes等则不属于任何namespace. Liveness probe: Kubernetes可以通过存活探针(liveness probe)检查容器是否还在运行,如果探测失败,Kubernetes将定期执行探针并重启容器. readinessProbe: Kubernetes可以定期调用就绪探针来确定特定的Pod是否接收客户端请求.当容器的准备就绪然测返回成功时,表示容器已准备好接收请求. Replication Controller(已弃用)：Replication Controller是一种Kubernetes资源，其工作时确保pod的数量始终与其标签选择器匹配。由三部分组成： lebel selector: 标签选择器，用于确定replicationcontroller作用域有哪些pod replica count:副本个数，指定应运行的pod数量 pod tepmlate: pod模板，用于创建新的pod模板 ReplicaSet：是 Pod 副本的抽象，用于解决 Pod 的扩容和伸缩. 相对于replicationController的主要改进是它更具表达力的标签选择器 通常不会直接创建,而是在创建更高级的Deployment资源时自动创建ReplicaSet. DaemonSet: DaemonSet保证每个Node上都运行一个容器副本,常用来部署一些集群的日志,监控或者其他系统管理应用.典型的应用包括: 日志收集:比如fluentd,logstash等 系统监控:比如Prometheus Node Exporter,collectd,New Relic agent,Ganglia gmond等 系统程序:比如kube-proxy,kube-dns等 Job: job资源允许你运行一种pod,该pod内部进程成功结束时,不重启容器.一旦任务完成,pod就被认为处于完成状态. Cronjob: 类似于Liunx操作系统中的cron任务,在特定的时间或者指定的时间间隔内,Kubernetes根据cronjob对象中配置的jobTemplate属性创建job资源,然后job创建pod. Deployment：Deployment 表示部署，在内部使用ReplicaSet 来实现。可以通过 Deployment 来生成相应的 ReplicaSet 完成 Pod 副本的创建 Service：Service 是 Kubernetes 最重要的资源对象。Service 定义了服务的访问入口，服务的调用者通过这个地址访问 Service 后端的 Pod 副本实例。Service 通过 Label Selector 同后端的 Pod 副本建立关系，Deployment 保证后端Pod 副本的数量，也就是保证服务的伸缩性。 NodePort: 使用一个集群固定IP,但是额外在每个Pod上均暴露这个服务和端口 LoadBalance: 使用集群固定IP,和NodePort,额外还会申请一个负载均衡器来转发到服务和端口 Ingress: 通常情况下,service和pod的IP仅可在集群内部访问.集群外部的请求需要通过负载均衡转发到service在Node上暴露的NodePort上,再由kube-proxy将其转发到相关的Pod.而Ingress就是为进入集群的请求提供路由规则的集合.Ingress可以给service提供集群外部访问的URL,负载均衡,ssl中止,HTTP路由等. headless: 简单理解为不需要Cluster的Service. emptyDir卷: 卷从一个空目录开始,运行在pod内的应用程序可以写入它需要的任何文件.卷的生命周期与pod的生命周期相关联,所以当删除pod时,卷的内容就会丢失. hostPath卷: hostPath卷指向节点文件系统上的指定文件或目录.hosPath卷的内容存储在特定节点的文件系统上,当pod被重新安排在另一个节点时,会找不到数据. PersistentVolume: 持久卷,简称PV,不属于任何命名空间,跟Node(节点)一样是集群层面的资源. PersistentVolumeClaim: 持久卷声明,简称PVC,集群用户需要在Pod中使用持久化存储时,首先要创建持久卷声明清单,指定所需要的最低容量要求和访问模式,然后提交给Kubernetes API 服务器,Kubernetes找到可匹配的持久卷并将其绑定到持久卷声明. ConfigMap: Kubernetes允许将配置选项分离到单独的资源对象ConfigMap中,本质是一个键/值对映射,值可以实短字面量,也可以是完整的配置文件. Secret: ConfigMap适用于传递非敏感数据,然而配置通常会包含一些敏感数据,如证书和私钥,为了存储这类信息,Kubernetes提供了Secret资源对象.Secret结构与ConfigMap类似,均是键/值对映射. 参考资料","tags":[{"name":"Kubernetes","slug":"Kubernetes","permalink":"http://saltci.xyz/tags/Kubernetes/"}],"categories":[{"name":"DevOps","slug":"DevOps","permalink":"http://saltci.xyz/categories/DevOps/"},{"name":"Kubernetes","slug":"DevOps/Kubernetes","permalink":"http://saltci.xyz/categories/DevOps/Kubernetes/"}]},{"title":"Docker使用指南","date":"2020-01-13T13:36:03.000Z","path":"DevOps/Docker/Docker使用指南/","text":"Docker容器使用 启动容器 12345docker run --name kubia-container -p 8080:8080 -d kubia# -d:后台运行docker run -it ubuntu /bin/bash# -i：交互式操作 -t:分配一个伪终端 /bin/bash:放在镜像名后的时命令# 使用exit退出终端 查看容器 123docker ps # 列出运行中的容器docker ps -a # 列出所有的容器docker inspect &lt;docker_name or docker_id&gt; # 获取更多的容器信息 进入容器 1234docker exec -it kubia-container bash# windows下使用该命令可能会遇到:the input device is not a tty,使用winpty解决问题# https://stackoverflow.com/questions/43099116/error-the-input-device-is-not-a-tty winpty docker exec -it some_cassandra bash 停止和删除容器 12docker stop kubia-containerdocker rm kubia-container 查看容器日志 1docker logs -f &lt;容器名 or 容器id&gt; Docker镜像使用 获取镜像 1docker pull python:3.6 查看镜像列表 12345docker images# REPOSITORY: 表示镜像仓库源# TAG: 镜像标签# IMAGE ID:镜像ID# CREATE: 镜像创建时间 查找镜像 1docker search httpd 删除镜像 1docker rmi &lt;镜像id or 镜像名&gt; 构建镜像 1docker build -t runoob/centos:6.7 . 设置镜像标签 1docker tag &lt;镜像id&gt; runoob/centos:dev Docker仓库管理 登录和退出 12docker logindocker logout 拉取镜像 1docker pull python:3.6 推送镜像 12docker tag kubia username/kubia # 使用附加标签标注镜像docker push username/kubia # 推送镜像 搜索镜像 1docker search username/kubia Dockerfile常用指令 FROM：基础镜像，后续操作都是基于这个基础镜像 MAINTAINER：用来指定维护者信息 1MAINTAINER xxx xxxx@example.com RUN： 用于执行后面跟着的命令行命令,在docker build时运行 COPY：复制指令，从上下文目录中复制文件或者目录到容器的制定路径 123456COPY [--chown=&lt;user&gt;:&lt;group&gt;] &lt;源路径1&gt;... &lt;目标路径&gt;# [--chown=&lt;user&gt;:&lt;group&gt;]：可选参数，用户改变复制到容器内文件的拥有者和属组# &lt;源路径&gt;:源文件或目录，这里可以是通配符表达式，起通配符规则要满足Go的filepath.Match规则，如:COPY hom* /mydir/COPY home?.txt /mydir/# &lt;目标路径&gt;:容器内制定路径，不存在则自动创建 ADD：和COPY的使用格式一致，功能类似，不同之处在于： ADD的优点：在执行&lt;源文件&gt;为tar压缩文件的话，压缩格式为gzip,bzip2以及xz的情况下，会自动复制并加压到&lt;目标路径&gt; ADD的缺点：在不解压的前提下，无法复制tar压缩文件。会令镜像构建缓存失效，从而可能会令镜像构建变得缓慢。具体是否使用，可以根据是否需要自动解压来决定。 CMD：类似于RUN命令，在docker run时运行 作用：为启动的容器制定要运行的程序，程序运行结束，容器也就结束。 注:如果Dockerfile中存在多个CMD指令，仅最后一个有效 会被docker run命令行参数中指定要运行的程序覆盖 123CMD command param1 param2 # 在/bin/bash 中执行，提供给需要交互的应用CMD [\"&lt;可执行文件或命令&gt;\",\"&lt;param1&gt;\",\"&lt;param2&gt;\"] # 使用exec执行，推荐方式CMD [\"&lt;param1&gt;\",\"&lt;param2&gt;\",...] # 为 ENTRYPOINT指令指定的程序提供默认参数 ENTRYPOINT：类似于CMD指令，不会被docker run的命令行参数指定的指令覆盖，这些命令行参数会被当做参数传递给ENTRYPOINT指令指定的程序。 12ENTRYPOINT [\"nginx\", \"-c\"] # 定参数CMD [\"/etc/nginx/nginx.conf\"] # 变参 ENV：定义环境变量，在后续的指令中，可以使用这个环境变量 12ENV &lt;key&gt; &lt;value&gt;ENV &lt;Key1&gt;=&lt;value1&gt; &lt;key2&gt;=&lt;value2&gt;... VOLUME：定义匿名数据卷。建议在启动容器docker run时，通过-v参数修改挂载点 EXPOSE：声明端口 WORKDIR：指定工作目录，会在构建镜像中的每一层都存在，WORKDIR指定的工作目录，必须是提前建好的。 Dockerfile示例1234567891011FROM python:3.6RUN mkdir -p /app &amp;&amp; mkdir -p /var/log/gunicornWORKDIR /appCOPY requirements.txt /app/requirements.txtRUN pip install -r requirements.txtCOPY . /appEXPOSE 80 8000CMD [\"gunicorn\",\"-w\",\"1\",\"-k\",\"gthread\",\"-b\",\"0.0.0.0:8000\",\"manage:app\"] 构建镜像 1docker build -t flask_project:test . 其它Linux无需sudo执行docker命令12341.创建一个docker用户组sudo groupadd docker2.添加当前用户到docker用户组sudo usermod -aG docker $USER 参考资料 Dockerfile详解以及Flask项目Dockerfile示例","tags":[{"name":"Docker","slug":"Docker","permalink":"http://saltci.xyz/tags/Docker/"}],"categories":[{"name":"DevOps","slug":"DevOps","permalink":"http://saltci.xyz/categories/DevOps/"},{"name":"Docker","slug":"DevOps/Docker","permalink":"http://saltci.xyz/categories/DevOps/Docker/"}]},{"title":"git常用命令总结","date":"2020-01-11T15:43:34.000Z","path":"Git/git常用命令总结/","text":"git pull时冲突的几种解决方式 使用git stash 命令进行处理 1234567891011121314151617181920# 1.先将本地修改存储起来git stash# 这样本地修改就都被暂时存储起来，使用git stash list可以查看保存的信息# 2.pull内容git pull# 3.还原暂存内容git stash pop stash@&#123;0&#125;# 然后系统会自动合并并修改内容，但是其中有冲突的地方需要解决其中的冲突# 4.解决文件中冲突的部分&lt;&lt;&lt;&lt;&lt;&lt;&lt; Updated upstream int i, j;======= int i, z;&gt;&gt;&gt;&gt;&gt;&gt;&gt; Stashed changes# Updated upstream 和=====之间的内容就是pull下来的内容# ====和stashed changes之间的内容就是本地修改的内容# 解决完之后就可以正常提交了 同一客户端使用多个git账号1234567891011121314151617181920212223242526272829303132333435# 1.生成多个SSH keyssh-keygen -t rsa -f ~/.ssh/id_rsa_two -C \"new mail\"# 2.配置~/.ssh/config文件# Default Github userHost one.github.com HostName github.com User one IdentityFile ~/.ssh/id_rsa_one# Second Github user# 建一个github别名，新建账号使用这个别名做克隆和更新Host two.github.com HostName github.com User two IdentityFile ~/.ssh/id_rsa_two# 3.测试ssh -T git@one.github.com# Hi IEIT! You've successfully authenticated, but GitHub does not provide shell access.# 出现上边这句，表示链接成功# 4.用户名和邮箱配置# 取消全局用户名和邮箱配置git config --global --unset user.namegit config --global --unset user.email# 设置局部 用户名/邮箱 配置git config user.name \"xxxx\"git config user.email \"xxx@xxx.com\"# 5.使用gitgit clone git@one.github.com:用户名/example.git# 已经存在的需要重建origingit remote rm origin # 清空origingit remote add origin git@one.github.com:one/example.gitgit push origin master 标签12345678910111213141516# 创建本地标签git tag v1.0.0# 指定commit打标签git tag v0.9 f52c633# 查看标签信息git show v0.9# 创建带说明的标签git tag -a v0.1 -m \"version 0.1 released\" 1094abd# 推送Tag到远程git push origin v1.0# 推送本地所有标签到远程git push origin --tags# 删除本地标签git tag --delete v1.0.0# 删除远程标签git push origin :refs/tags/v1.0.0 参考资料 同一客户端下使用多个git账号 同一台电脑上使用两个 github 账号","tags":[{"name":"git","slug":"git","permalink":"http://saltci.xyz/tags/git/"}],"categories":[{"name":"Git","slug":"Git","permalink":"http://saltci.xyz/categories/Git/"}]},{"title":"Welcome Saltci's Wiki Site","date":"2020-01-11T12:11:57.000Z","path":"index/","text":"这是 saltci 的个人 Wiki 站点，使用基于Hexo的Wiki主题hexo-theme-Wikitten来记录一些只言片语。","tags":[],"categories":[]}]}